<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/tag_data.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2016-10-09T00:00:00+00:00</updated><entry><title>Becoming a Data Scientist Advice From My Podcast Guests</title><link href="http://pyvideo.org/pydata-dc-2016/becoming-a-data-scientist-advice-from-my-podcast-guests.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Renee Teate</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/becoming-a-data-scientist-advice-from-my-podcast-guests.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Overwhelmed by the vast resources (of varying quality) available online for learning data science? In this talk, I compile resources from data scientists on twitter, advice from guests of my podcast, and some of my own experience to help get you started on the path to Becoming a Data Scientist.&lt;/p&gt;
&lt;p&gt;The options for learning data science online are vast and overwhelming, but it is possible to find great resources that work well for you and learn data science without going back to school if you know how to approach it.&lt;/p&gt;
&lt;p&gt;On my &amp;quot;Becoming a Data Scientist&amp;quot; podcast, I have interviewed 17 data scientists (or those on the way to becoming data scientists) about their career paths and how they learned data science. I also interact with hundreds of data scientists regularly on Twitter. In this talk, I compile the frequent advice and the best resources, and give my answers to some common questions about how to become a data scientist.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>Data Transformation: A Framework for Exploratory Data Analysis</title><link href="http://pyvideo.org/pydata-dc-2016/data-transformation-a-framework-for-exploratory-data-analysis.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Tony Ojeda</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/data-transformation-a-framework-for-exploratory-data-analysis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Exploratory data analysis plays a critical role in the job of every data scientist, but very few have a structured process or framework for exploring data quickly and efficiently. This talk will introduce the exploratory framework I use in my day-to-day work and will walk attendees through a practical example of how to use the framework to unlock hidden insights with the help of Python libraries.&lt;/p&gt;
&lt;p&gt;At the heart of data analysis, there lies a need to understand the real world entities being represented in the data. Every data set we encounter is an attempt to capture a slice of our complex world and communicate some information about it in a way that has potential to be informative to humans, machines, or both. Moving from basic analyses to advanced analytics requires the ability to imagine multiple ways of conceptualizing the composition of entities and the relationships present in our data. It also requires the realization that different levels of aggregation, disaggregation, and transformation can open up new pathways to understanding our data and identifying the valuable insights it contains.&lt;/p&gt;
&lt;p&gt;In this talk, we’ll discuss several ways to think about the composition and representation of our data. We’ll also demonstrate a series of methods that leverage tools like networks, hierarchical aggregations, and unsupervised clustering to visually explore our data, transform it to discover new insights, help frame analytical problems and questions, and even improve machine learning model performance. In exploring these approaches, and with the help of Python libraries such as Pandas, Scikit-Learn, Seaborn, and NetworkX, we will provide a practical framework for thinking creatively and visually about your data and unlocking latent value and insights hidden deep beneath its surface.&lt;/p&gt;
</summary><category term="analysis"></category><category term="Data"></category><category term="Data Analysis"></category><category term="framework"></category></entry><entry><title>Dev Ops meets Data Science Taking models from prototype to production with Docker</title><link href="http://pyvideo.org/pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Andy Terrel</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;We present the evolution of a model to a production API that can scale to large e-commerce needs. On the journey we discuss metrics of success and how to use the Kubernetes cluster manager and associated tools for deploy. In addition to the use of these tools we highlight how to make use of the cluster management system for further testing and experimentation with your models.&lt;/p&gt;
&lt;p&gt;The chasm between data science and dev ops is often wide and impenetrable, but the two fields have more in common than meets the eye. Every data scientist will be able to lean in and help their career by investing in a basic understanding the basic principles of dev ops. In this talk I present the notions of service level indicators, objectives, and agreements. I cover the rigorous monitoring and testing of services. Finally we demonstrate how to build a basic data science workflow and push to production level APIs with Docker and Kubernetes.&lt;/p&gt;
&lt;p&gt;Kubernetes is an opinionated container cluster manager with an easy to use, robust interface. It can be use on very small and very large clusters. Docker is a container system that allows one to build code in an isolated environment. Paired with a container manager such as Kubernetes we are able to manage millions of instances as needed for a production deployment. These tools are two of many different options but are considered among the best open source solutions available.&lt;/p&gt;
</summary><category term="Data"></category><category term="data science"></category><category term="docker"></category><category term="models"></category><category term="science"></category></entry><entry><title>Keynote: Extending from Open to Usable: A Commerce Data Conundrum</title><link href="http://pyvideo.org/pydata-dc-2016/keynote-extending-from-open-to-usable-a-commerce-data-conundrum.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Star Ying</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/keynote-extending-from-open-to-usable-a-commerce-data-conundrum.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Keynote: Extending from Open to Usable: A Commerce Data Conundrum&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>Keynote: The Culture of Data Transformation</title><link href="http://pyvideo.org/pydata-dc-2016/keynote-the-culture-of-data-transformation.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>SriSatish Ambati</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/keynote-the-culture-of-data-transformation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
</summary><category term="Culture"></category><category term="Data"></category></entry><entry><title>Open Data Dashboards &amp; Python Web Scraping</title><link href="http://pyvideo.org/pydata-dc-2016/open-data-dashboards-python-web-scraping.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Marie Whittaker</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/open-data-dashboards-python-web-scraping.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Distilling a world of data down to a few key indicators can be an effective way of keeping an audience informed, and this concept is at the heart of a good dashboard. This talk will cover a few methods of scraping and reshaping open data for dashboard visualization, to automate the boring stuff so you have more time and energy to focus on the analysis and content.&lt;/p&gt;
&lt;p&gt;This talk will cover a basic scenario of curating open data into visualizations for an audience. The main goal is to automate data scraping/downloading and reshaping. I use python to automate data gathering, and Tableau and D3 as visualization tools -- but the process can be applied to numerous analytical/visualization suites.&lt;/p&gt;
&lt;p&gt;I'll discuss situations where a dashboard makes sense (and when one doesn't). I will make a case also that automation makes for a more seamless data gathering and updating process, but not always for smarter data analysis.&lt;/p&gt;
&lt;p&gt;Some python packages I'll cover for web scraping and downloading/reshaping open data include: openpyxl, pandas, xlsxwriter, and BeautifulSoup. I'll also touch on APIs.&lt;/p&gt;
</summary><category term="Data"></category><category term="scraping"></category><category term="web"></category></entry><entry><title>Triaging Feedback Form Data</title><link href="http://pyvideo.org/pydata-dc-2016/triaging-feedback-form-data.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Stephanie Kim</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/triaging-feedback-form-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;This talk will cover how to use predictive modeling on unstructured text data including feedback form, social media or chat message data to triage issues in order to prevent future problems with a service, platform or user interface using NLP techniques in Python and R.&lt;/p&gt;
&lt;p&gt;Companies gain useful insights about their users from feedback form and other unstructured text data including live chat messages. Even though they are read and responded to, often such data is ignored when thinking about larger scale trend analysis and this can result in missed insight about how users react to a product or service. Sometimes analysis is being done by looking at changes in user sentiment or other heuristics, however it could be taken a step further by applying predictive modeling in attempt to recognize areas that need more attention and support. While you can use predictive modeling on network and log data, that is looking at how the hardware is handling your users requests, not how it's being perceived by users. By predicting areas where users are having difficulty whether it's with the UI or with the platform's response time you can triage these areas of concern to prevent future cases of negative perception. This talk will cover how to utilize common NLP tools used to gather and process the features in Python then will use R to perform trend analysis and predictive modeling then use the results to triage what areas should be focused on in the future.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>You got your engineering in my Data Science: Addressing the reproducibility crisis</title><link href="http://pyvideo.org/pydata-dc-2016/you-got-your-engineering-in-my-data-science-addressing-the-reproducibility-crisis.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Jon Bodner</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/you-got-your-engineering-in-my-data-science-addressing-the-reproducibility-crisis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/jonbodner/you-got-your-engineering-in-my-data-science-addressing-the-reproducibility-crisis-with-software-engineering"&gt;http://www.slideshare.net/jonbodner/you-got-your-engineering-in-my-data-science-addressing-the-reproducibility-crisis-with-software-engineering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data science is the backbone of modern scientific discovery and industry. Unfortunately, multiple recent studies have been found to be unreliable and non-reproducible. Adopting techniques from software engineering might help mitigate some of these problems.&lt;/p&gt;
&lt;p&gt;Data science is the backbone of modern scientific discovery and industry. It makes sense of everything from cancer trials to package delivery logistics. But all is not well with data science. Over the past decade, multiple studies have been found to be unreliable and non-reproducible when other scientists tried to recreate their results. This is due to a variety of factors, including fraud, pressure to publish, improper data handling practices, and bugs in analytic tools.&lt;/p&gt;
&lt;p&gt;The problems faced by data science mirror problems that software engineering has been trying to solve. While there are no silver bullets to guarantee quality software, techniques have been developed over time that have improved quality and reliability. Some of these techniques, including open source, version control, automation, and fuzzing could be adapted to the data science domain to improve reliability and help address the reproducibility crisis.&lt;/p&gt;
</summary><category term="Data"></category><category term="data science"></category><category term="engineering"></category><category term="reproducibility"></category></entry><entry><title>Creating Python Data Pipelines in the Cloud</title><link href="http://pyvideo.org/pydata-dc-2016/creating-python-data-pipelines-in-the-cloud.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Femi Anthony</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/creating-python-data-pipelines-in-the-cloud.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;My talk will be an analysis of the various approaches to creating data pipelines the public cloud using Python.I will compare and contrast using various Python libraries such as Luigi, Airflow and native cloud frameworks such as Cloud Dataflow (Google), AWS Data Pipeline to create a real world data pipeline in Amazon AWS and Google Compute Engine.&lt;/p&gt;
</summary><category term="Cloud"></category><category term="Data"></category></entry><entry><title>Data Sciencing While Female</title><link href="http://pyvideo.org/pydata-dc-2016/data-sciencing-while-female.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Mandi Traud</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/data-sciencing-while-female.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;How can we increase the number of female data scientists in the workplace? By building a community. Dr. Amanda Traud was the only woman on her data science team when she started the group Women Data Scientists DC. In one year, the group grew to over 1,000 members. Dr. Traud will discuss the ups and downs of being a woman in data science and how to encourage and include more women in the field.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>Eat Your Vegetables Data Security for Data Scientists</title><link href="http://pyvideo.org/pydata-dc-2016/eat-your-vegetables-data-security-for-data-scientists.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Will Voorhees</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/eat-your-vegetables-data-security-for-data-scientists.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/WilliamVoorhees1/eat-your-vegetables-data-security-for-data-scientists"&gt;http://www.slideshare.net/WilliamVoorhees1/eat-your-vegetables-data-security-for-data-scientists&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You've got data: lots of it. People want to get their hands on that data. You don't want that, so let's go over a few things you can do to dissuade attackers from getting their grubby mitts on your hard processed datastore. We'll cover the obvious things (spoiler alert: encryption) and then some advanced techniques for keeping data secure while still keeping it usable (that is to say, analyzable).&lt;/p&gt;
</summary><category term="Data"></category><category term="Security"></category></entry><entry><title>Forecasting critical food violations at restaurants using open data</title><link href="http://pyvideo.org/pydata-dc-2016/forecasting-critical-food-violations-at-restaurants-using-open-data.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Nicole Donnelly</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/forecasting-critical-food-violations-at-restaurants-using-open-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Dc 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/NicoleDonnelly6/pydatadc-forecasting-critical-food-violations-at-restaurants-using-open-data"&gt;http://www.slideshare.net/NicoleDonnelly6/pydatadc-forecasting-critical-food-violations-at-restaurants-using-open-data&lt;/a&gt;
Github: &lt;a class="reference external" href="https://github.com/nd1/DC_RestaurantViolationForecasting"&gt;https://github.com/nd1/DC_RestaurantViolationForecasting&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As many as 105 million Americans suffer from foodborne illness annually. In 2014, the City of Chicago began forecasting these outbreaks targeting limited health inspection resources toward likely sites, showing a 7 day improvement in locating critical violations at food establishments. This talk provides an end-to-end walkthrough of predicting critical violations in Washington, DC using Python.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>How I learned to time travel, or, data pipelining and scheduling with Airflow</title><link href="http://pyvideo.org/pydata-dc-2016/how-i-learned-to-time-travel-or-data-pipelining-and-scheduling-with-airflow.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Laura Lorenz</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/how-i-learned-to-time-travel-or-data-pipelining-and-scheduling-with-airflow.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/PyData/how-i-learned-to-time-travel-or-data-pipelining-and-scheduling-with-airflow-67650418"&gt;http://www.slideshare.net/PyData/how-i-learned-to-time-travel-or-data-pipelining-and-scheduling-with-airflow-67650418&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data warehousing and analytics projects can, like ours, start out small - and fragile. With an organically growing mess of scripts glued together and triggered by cron jobs hiding on different servers, we needed better plumbing. After perusing the data pipelining landscape, we landed on Airflow, an Apache incubating batch processing pipelining and scheduler tool from Airbnb.&lt;/p&gt;
</summary><category term="airflow"></category><category term="Data"></category></entry><entry><title>Keynote: Become a Data Superhero How Data Can Change the World</title><link href="http://pyvideo.org/pydata-dc-2016/keynote-become-a-data-superhero-how-data-can-change-the-world.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Elizabeth Lindsey</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/keynote-become-a-data-superhero-how-data-can-change-the-world.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;The capacity to gather and interpret data can be low for many nonprofits. Working together, data scientists and organizations can be a world-changing combination. Byte Back has found a way to use data analysis for good and will help you learn how to tap into your own superpowers.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>Keynote: Building a Data Driven Dialogue From Filling Potholes to Disrupting the Cycle</title><link href="http://pyvideo.org/pydata-dc-2016/keynote-building-a-data-driven-dialogue-from-filling-potholes-to-disrupting-the-cycle.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Kelly Jin</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/keynote-building-a-data-driven-dialogue-from-filling-potholes-to-disrupting-the-cycle.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>Keynote: How Open Data Science Opens the World of Innovation</title><link href="http://pyvideo.org/pydata-dc-2016/keynote-how-open-data-science-opens-the-world-of-innovation.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Robert Cohn</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/keynote-how-open-data-science-opens-the-world-of-innovation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Innovation today appears to be instantaneous in large part due to open source technology. Open Data Science is no exception. Python, a pillar in the Open Data Science bedrock, is well positioned to harvest innovation in software and with Anaconda, it’s also well positioned to capitalize on the latest hardware innovations. Anaconda and Intel are blazing a path for the Python community to take advantage of cognitive computing, including machine learning and deep learning.&lt;/p&gt;
&lt;p&gt;In this keynote, Peter and Robert will talk about how Open Data Science––a connected ecosystem of data, analytics and compute––streamlines the path to high performance and innovation to achieve breakthrough results.&lt;/p&gt;
</summary><category term="Data"></category><category term="data science"></category><category term="science"></category></entry><entry><title>Promoting a data driven culture in a world of microservices</title><link href="http://pyvideo.org/pydata-dc-2016/promoting-a-data-driven-culture-in-a-world-of-microservices.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Alex DeBrie</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/promoting-a-data-driven-culture-in-a-world-of-microservices.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/PyData/promoting-a-data-driven-culture-in-a-microservices-environment"&gt;http://www.slideshare.net/PyData/promoting-a-data-driven-culture-in-a-microservices-environment&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;At Hudl, we give every employee full access to our data warehouse, and over 50% of our employees have personally written a query against it. In this talk, I discuss our journey to democratize our data. I touch on technical and non-technical challenges, including the tools we use and the structure of our teams.&lt;/p&gt;
</summary><category term="Culture"></category><category term="Data"></category></entry><entry><title>Scaling up to Big Data Devops for Data Science</title><link href="http://pyvideo.org/pydata-dc-2016/scaling-up-to-big-data-devops-for-data-science.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Marck Vaisman</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/scaling-up-to-big-data-devops-for-data-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Scaling up R/Python from a single machine to a cluster environment can be tricky. While there are many tools available that make the launching of a cluster relatively easy, they are not focused or optimized to the specific use case of analytics but mostly on operations. Come and learn about devops tips and tricks to optimize your transition into the big data world as a data scientist.&lt;/p&gt;
</summary><category term="big data"></category><category term="Data"></category><category term="data science"></category><category term="devops"></category><category term="scaling"></category><category term="science"></category></entry><entry><title>Building Your First Data Pipelines</title><link href="http://pyvideo.org/pydata-dc-2016/building-your-first-data-pipelines.html" rel="alternate"></link><published>2016-10-07T00:00:00+00:00</published><updated>2016-10-07T00:00:00+00:00</updated><author><name>Hunter Owens</name></author><id>tag:pyvideo.org,2016-10-07:pydata-dc-2016/building-your-first-data-pipelines.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;You need a data pipeline. This talk will discuss the lifecycle of projects using Jupyter notebooks &amp;amp; Luigi as a data pipeline management tool for a variety of projects, from greenfield to retrofitting complex systems. It will included a hands on demo.&lt;/p&gt;
&lt;p&gt;Data pipelines are hard. Too often we resort to retrofitting janky scripts, relying on keeping a readme up to data, etc.&lt;/p&gt;
&lt;p&gt;First, this proposal lays out the variety of tools that are available to build data pipelines. This talk will discuss why you should be using Luigi and how to use it in a variety of common use cases.&lt;/p&gt;
&lt;p&gt;Next, we will build a basic exploratory analysis using DC open data and Luigi to demonstrate the power of this concept and how it works with Jupyter.&lt;/p&gt;
&lt;p&gt;Finally, we'll retrofit a larger, more complex project to use Luigi to show how you can use it in bigger organizations.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>Parallel Python Analyzing Large Data Sets</title><link href="http://pyvideo.org/pydata-dc-2016/parallel-python-analyzing-large-data-sets.html" rel="alternate"></link><published>2016-10-07T00:00:00+00:00</published><updated>2016-10-07T00:00:00+00:00</updated><author><name>Aron Ahmadia</name></author><id>tag:pyvideo.org,2016-10-07:pydata-dc-2016/parallel-python-analyzing-large-data-sets.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Students will walk away with a high-level understanding of both parallel problems and how to reason about parallel computing frameworks. They will also walk away with hands-on experience using a variety of frameworks easily accessible from Python.&lt;/p&gt;
</summary><category term="Data"></category><category term="parallel"></category><category term="sets"></category></entry><entry><title>Finding Driving Style Patterns in Caterpillar Machine Data</title><link href="http://pyvideo.org/pydata-chicago-2016/finding-driving-style-patterns-in-caterpillar-machine-data.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Benjamin Hodel</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/finding-driving-style-patterns-in-caterpillar-machine-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://cat.app.box.com/s/1c4mvt8eayb5o7g2wp8nsdwbguhgersm"&gt;https://cat.app.box.com/s/1c4mvt8eayb5o7g2wp8nsdwbguhgersm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Identifying predominant driving-style patterns in logged time series data of Caterpillar machines is daunting due to the nature and size of the data. However, insight gained from field data can deliver optimized powertrain control software and better machine performance. A solution for finding patterns was built using engineered features, dimensionality reduction, and unsupervised learning.&lt;/p&gt;
</summary><category term="Data"></category><category term="patterns"></category><category term="style"></category></entry><entry><title>Machine learning techniques for data cleaning</title><link href="http://pyvideo.org/pydata-chicago-2016/machine-learning-techniques-for-data-cleaning.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Cathy Deng</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/machine-learning-techniques-for-data-cleaning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1k42esoWoc_WezfPfQ5vxbHTsuFOvAshEusD-GFCElTQ/edit#slide=id.g166bf446d8_1_12"&gt;https://docs.google.com/presentation/d/1k42esoWoc_WezfPfQ5vxbHTsuFOvAshEusD-GFCElTQ/edit#slide=id.g166bf446d8_1_12&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Often, the most interesting datasets - data about people and organizations - are the messiest and most difficult to analyze. When data comes from multiple sources, or when data is entered manually, variation &amp;amp; ambiguity are inevitable. Learn about ways to infer structure and relationships in messy data, using open source Python libraries.&lt;/p&gt;
</summary><category term="Data"></category><category term="learning"></category><category term="machine learning"></category></entry><entry><title>Using Exploratory Data Analysis to Discover Patterns in Image and Document Collections</title><link href="http://pyvideo.org/pydata-chicago-2016/using-exploratory-data-analysis-to-discover-patterns-in-image-and-document-collections.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Mehrdad Yazdani</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/using-exploratory-data-analysis-to-discover-patterns-in-image-and-document-collections.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1StRN0-_0x4BPkFFQ79GusgQAqXgwvJ1Fc8Tlu68YO4E/edit"&gt;https://docs.google.com/presentation/d/1StRN0-_0x4BPkFFQ79GusgQAqXgwvJ1Fc8Tlu68YO4E/edit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Exploratory Data Analysis (EDA) is one of the key sets of procedures for summarizing a dataset. In this talk we will develop an EDA procedure for large collections of documents and images (such as photo albums, emails, articles, etc). We will show features used from NLP and Deep Neural Nets and also introduce novel visualization techniques for large image collections using PyImagePlot.&lt;/p&gt;
</summary><category term="analysis"></category><category term="Data"></category><category term="data analysis"></category><category term="patterns"></category></entry><entry><title>When Worlds Collide: Productionalizing a Data Science Model</title><link href="http://pyvideo.org/pydata-chicago-2016/when-worlds-collide-productionalizing-a-data-science-model.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Tudor Radoaca</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/when-worlds-collide-productionalizing-a-data-science-model.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;On our first data science project at Shiftgig, the data science and engineering teams had to build software that was production-ready while maintaining the flexibility of a data science sandbox. Although these seem like irreconcilable goals, they forced us to improve inter-team communication and ultimately helped create a great product. We’ll walk through our process and the lessons we learned.&lt;/p&gt;
</summary><category term="Data"></category><category term="data science"></category><category term="model"></category><category term="science"></category></entry><entry><title>Data Engineering Architecture at Simple</title><link href="http://pyvideo.org/pydata-chicago-2016/data-engineering-architecture-at-simple.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Rob Story</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/data-engineering-architecture-at-simple.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;A walk through Simple's Data Engineering stack, including lessons learned and why we chose certain tools and languages for different parts of our infrastructure.&lt;/p&gt;
</summary><category term="architecture"></category><category term="Data"></category><category term="engineering"></category></entry><entry><title>Keynote: Using Data Science for Social Good: Examples, Opportunities, and Challenges</title><link href="http://pyvideo.org/pydata-chicago-2016/keynote-using-data-science-for-social-good-examples-opportunities-and-challenges.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Rayid Ghani</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/keynote-using-data-science-for-social-good-examples-opportunities-and-challenges.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
</summary><category term="Data"></category><category term="data science"></category><category term="science"></category></entry><entry><title>What Data Analysts Wish Application Developers Knew</title><link href="http://pyvideo.org/pydata-chicago-2016/what-data-analysts-wish-application-developers-knew.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Alison Stanton</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/what-data-analysts-wish-application-developers-knew.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://speakerdeck.com/alison985/what-data-analysts-wish-application-developers-knew"&gt;https://speakerdeck.com/alison985/what-data-analysts-wish-application-developers-knew&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data analysts frequently do not get to participate in the app development process despite being some of its biggest stakeholders. This talk focuses on general guidelines and best practices for application developers on what they can do to optimize data content and quality available for analysis.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>Luigi &amp; Data Pipelines</title><link href="http://pyvideo.org/pydata-chicago-2016/luigi-data-pipelines.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Hunter Owens</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/luigi-data-pipelines.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/hunterowens/data-pipelines"&gt;https://github.com/hunterowens/data-pipelines&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You need a data pipeline. This talk will discuss the lifecycle of projects using Jupyter notebooks &amp;amp; Luigi as a data pipeline management tool for a variety of projects, from greenfield to retrofitting complex systems. It will included a hands on demo.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>Working with real-time data streams in Python</title><link href="http://pyvideo.org/pycon-au-2016/working-with-real-time-data-streams-in-python.html" rel="alternate"></link><published>2016-08-12T00:00:00+00:00</published><updated>2016-08-12T00:00:00+00:00</updated><author><name>Lachlan Blackhall</name></author><id>tag:pyvideo.org,2016-08-12:pycon-au-2016/working-with-real-time-data-streams-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;An increasing number of devices and applications are producing vast amounts of data in real time. This can include measurements, sensor readings, and performance data. Making this data useful often requires that we analyse and use the data in real time but this requires techniques to aggregate, filter, and smooth the data. Drawing on simple and well-tested techniques from mathematics and engineering allows us to solve these problems quickly and efficiently. This talk will describe how Python can be used to develop powerful capabilities for working with real-time data streams and provide simple examples you can start using yourself.&lt;/p&gt;
</summary><category term="Internet-of-Things"></category><category term="Data"></category><category term="Real-time"></category><category term="Kalman Filter"></category></entry><entry><title>PyGotham 2011: Intro to Data Visualization</title><link href="http://pyvideo.org/pygotham-2011/pygotham-2011--intro-to-data-visualization.html" rel="alternate"></link><published>1990-01-01T00:00:00+00:00</published><updated>1990-01-01T00:00:00+00:00</updated><author><name>Julie Steele</name></author><id>tag:pyvideo.org,1990-01-01:pygotham-2011/pygotham-2011--intro-to-data-visualization.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Have lots of data? Want to turn it into pictures to help you better
understand it or explain it to others? This session will address best
practices for encoding information through design, and will look at a
few ways of doing this in Python.&lt;/p&gt;
</summary><category term="data"></category><category term="pygotham"></category><category term="pygotham2011"></category><category term="visualization"></category></entry><entry><title>Data mining and integration with Python</title><link href="http://pyvideo.org/pytexas-2015/data-mining-and-integration-with-python.html" rel="alternate"></link><published>2015-10-09T00:00:00+00:00</published><updated>2015-10-09T00:00:00+00:00</updated><author><name>Isaac Vidas</name></author><id>tag:pyvideo.org,2015-10-09:pytexas-2015/data-mining-and-integration-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There is an abundance of data in social media sites (Wikipedia,
Facebook, Instagram, etc.) which can be accessed through web APIs. But
how do we know that the data from the Wikipedia article on &amp;quot;Golden Gate
Bridge&amp;quot; goes along with the data from &amp;quot;Golden Gate Bridge&amp;quot; Facebook
page? This represents an important question about integrating data from
various sources.&lt;/p&gt;
&lt;p&gt;In this talk, I'll outline important aspects of structured data mining,
integration and entity resolution methods in a scalable system.&lt;/p&gt;
</summary><category term="Data"></category><category term="Data Analysis"></category><category term="data mining"></category></entry><entry><title>Real-Time Django</title><link href="http://pyvideo.org/djangocon-2011/djangocon-2011--real-time-django.html" rel="alternate"></link><published>1990-01-01T00:00:00+00:00</published><updated>1990-01-01T00:00:00+00:00</updated><author><name>Adam Miskiewicz</name></author><id>tag:pyvideo.org,1990-01-01:djangocon-2011/djangocon-2011--real-time-django.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Real-Time Django&lt;/p&gt;
&lt;p&gt;Presented by Ben Slavin, Adam Miskiewicz&lt;/p&gt;
&lt;p&gt;The web is live. APIs give us access to continuously changing data. We
discuss ways to get real-time data into your app, how to handle data
processing and what to do when you get thousands of updates per second.&lt;/p&gt;
</summary><category term="data"></category><category term="djangocon"></category><category term="djangocon2011"></category><category term="realtime"></category></entry><entry><title>Guy Kloss - Python Data Plotting and Visualisation Extravaganza</title><link href="http://pyvideo.org/kiwi-pycon-2009/guy-kloss---python-data-plotting-and-visualisatio.html" rel="alternate"></link><published>1990-01-01T00:00:00+00:00</published><updated>1990-01-01T00:00:00+00:00</updated><author><name>Guy Kloss</name></author><id>tag:pyvideo.org,1990-01-01:kiwi-pycon-2009/guy-kloss---python-data-plotting-and-visualisatio.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python Data Plotting and Visualization Extravaganza&lt;/p&gt;
&lt;p&gt;Presented by Guy Kloss&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In various fields data is accumulated or produced. This can be
observation data, statistical data, simulation data, ... Information
like that can in many cases be much more easily analysed through the
user's eyes employing data visualisation. This talk is trying to dive
briefly into various means and tools to visually analyse data of
different qualities: time series, simple 2D plots, surface plots, volume
plots, quiver plots, etc.&lt;/p&gt;
&lt;p&gt;Outline&lt;/p&gt;
&lt;p&gt;I am planning on doing a &amp;quot;fly by&amp;quot; through the world of data
visualisation for different types of data using different tools. Types
of data:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1D data and simple functions&lt;/li&gt;
&lt;li&gt;2D data for surface plots&lt;/li&gt;
&lt;li&gt;3D data through quiver plots, iso surfaces, and cutting planes&lt;/li&gt;
&lt;li&gt;n-D data through different means&lt;/li&gt;
&lt;li&gt;continuous and non-continuously structured data&lt;/li&gt;
&lt;li&gt;time series&lt;/li&gt;
&lt;li&gt;real time data visualisation/analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The tools that will probably appear in the demos and discussions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;GNUplot&lt;/li&gt;
&lt;li&gt;matplotlib&lt;/li&gt;
&lt;li&gt;Mayavi2&lt;/li&gt;
&lt;li&gt;Visual Python&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[VIDEO HAS ISSUES: Sound and video are poor. Slides are hard to read.]&lt;/p&gt;
</summary><category term="data"></category><category term="gnuplot"></category><category term="kiwipycon"></category><category term="kiwipycon2009"></category><category term="matplotlib"></category><category term="mayavi2"></category><category term="plotting"></category><category term="visualpython"></category></entry></feed>