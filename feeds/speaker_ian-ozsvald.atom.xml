<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/speaker_ian-ozsvald.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2017-05-06T00:00:00+00:00</updated><entry><title>Machine learning with ventilator data to improve reporting on critically ill newborn infants</title><link href="http://pyvideo.org/pydata-london-2017/machine-learning-with-ventilator-data-to-improve-reporting-on-critically-ill-newborn-infants.html" rel="alternate"></link><published>2017-05-06T00:00:00+00:00</published><updated>2017-05-06T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2017-05-06:pydata-london-2017/machine-learning-with-ventilator-data-to-improve-reporting-on-critically-ill-newborn-infants.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Description
Mechanical ventilators are widely used in intensive care, they are sophisticated but Doctors do not have time to analyse the copious traces of data in a neonatal unit. We are providing an easy-to-interpret summary of this time-series data using visualisation and machine learning. This is an open source collaboration with the NHS, All results are open.&lt;/p&gt;
&lt;p&gt;Abstract
Mechanical ventilators are widely used in intensive care. Even two decades ago they were be primarily mechanical devices whose &amp;quot;only&amp;quot; task was to inflate the patient’s lung. Recently, however, they have become equipped with powerful computers that provide sophisticated ventilator modes. Data provided by the ventilators are almost never downloaded, stored or analysed. The data is complex, high frequency and requires time-intensive scrutiny to review. Doctors do not have time to analyse these traces in a neonatal unit.&lt;/p&gt;
&lt;p&gt;We are providing a simple and easy-to-interpret summary of 100Hz dual-channel ventilator data to improve the quality of care of young infants by time-poor staff. This involves signal processing, visualisation, building a gold standard and machine learning to segment breaths and summarise a baby's behaviour. This builds on our talk at PyDataLondon Meetup 30 in January 2017. Our goal is to open source the research so that others can benefit from the processes that we develop. We invite feedback from the audience to help improve our methods.&lt;/p&gt;
&lt;p&gt;Anyone interested in time series data, automated labeling, scikit-learn, Bokeh and medical applications will find this talk of interest. Both the highs and lows of our current approaches will be discussed.&lt;/p&gt;
&lt;p&gt;This is a collaboration between Dr Gusztav Belteki (Cambridge University Hopsitals NHS Foundation Turst), Ian Ozsvald (ModelInsight) and Giles Weaver (ModelInsight).&lt;/p&gt;
</summary></entry><entry><title>The High Performance Python Landscape</title><link href="http://pyvideo.org/pycon-uk-2014/the-high-performance-python-landscape.html" rel="alternate"></link><published>2014-10-14T00:00:00+00:00</published><updated>2014-10-14T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2014-10-14:pycon-uk-2014/the-high-performance-python-landscape.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Presented by: Ian Ozsvald&lt;/p&gt;
&lt;p&gt;A Python programmer has many options to profile and optimize CPU-bound and data-bound systems, common solutions include Cython, numpy and PyPy. Increasingly we have single-core solutions that should take advantage of many cores and clusters. This talk reviews the current state of the art, looking at the compromises and outcomes of the current approaches and reviews upcoming solutions like Numba, Pythran and PyPy’s numpy and STM. Thoughts will be shared on how current hindrances might be improved.&lt;/p&gt;
</summary></entry><entry><title>Using Machine Learning to solve a classification problem with scikit-learn</title><link href="http://pyvideo.org/pycon-uk-2016/using-machine-learning-to-solve-a-classification-problem-with-scikit-learn.html" rel="alternate"></link><published>2016-09-18T00:00:00+00:00</published><updated>2016-09-18T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2016-09-18:pycon-uk-2016/using-machine-learning-to-solve-a-classification-problem-with-scikit-learn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Ian Ozsvald&lt;/p&gt;
&lt;p&gt;This talk is aimed at developers who want to use machine learning to solve their own binary (2 class) classification task. No prior machine learning or math experience is required. This talk will cover feature engineering (including a robust solution to 'the problem of null data'), predicting the right class with a Random Forest, cross-validating to avoid over-fitting, diagnosing problems in the classifier and approaches to deploying the classifier in the real world. My goal is to provide you with a process that you can take back to the office to try with your own data. It'll be backed by reproducible working code.&lt;/p&gt;
</summary></entry><entry><title>Data Cleaning on Text to Prepare for Analysis and Machine Learning</title><link href="http://pyvideo.org/euroscipy-2015/data-cleaning-on-text-to-prepare-for-analysis-and-machine-learning.html" rel="alternate"></link><published>2015-10-05T00:00:00+00:00</published><updated>2015-10-05T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2015-10-05:euroscipy-2015/data-cleaning-on-text-to-prepare-for-analysis-and-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dirty data makes analysis and machine learning harder (or impossible!) and more prone to failure. I'll talk on the techniques we use at ModelInsight to fix badly encoded, inconsistent and hard-to-parse text data that enable us to prepare real-world industrial data for research.&lt;/p&gt;
</summary></entry><entry><title>Statistically Speculating on the Source of Sneezes and Sniffles</title><link href="http://pyvideo.org/pydata-london-2016/ian-ozsvald-statistically-speculating-on-the-source-of-sneezes-and-sniffles.html" rel="alternate"></link><published>2016-05-31T00:00:00+00:00</published><updated>2016-05-31T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2016-05-31:pydata-london-2016/ian-ozsvald-statistically-speculating-on-the-source-of-sneezes-and-sniffles.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Berlin 2016&lt;/p&gt;
&lt;p&gt;Since April 2015 our group has studied the Allergic Rhinitis of a subject with the goal of building a machine learned model that predicts the need for antihistamines. Approximately 30% of the world's population suffers from allergies, we aim to provide a methodology for others to identify the drivers of their own symptoms. This is a &amp;quot;citizen science&amp;quot; project, currently focused on one individual and a year's worth of self-reported antihistamine usage, sneezing data and geolocated points. We'll discuss the available external data (including the London Air project's pollution readings, weather, diet, exercise and commute data), exploratory data analysis, our approach to feature engineering from time-series and text sources and our modeling progress. The data logging iPhone app and data preparation tools are all open sourced. Python tools discussed include scikit-learn, seaborn, statsmodels and textract. We'll also review our distributed working practices.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://speakerdeck.com/ianozsvald/statistically-solving-sniffles-step-by-step-a-work-in-progress"&gt;https://speakerdeck.com/ianozsvald/statistically-solving-sniffles-step-by-step-a-work-in-progress&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More information: &lt;a class="reference external" href="http://ianozsvald.com/2016/05/07/statistically-solving-sneezes-and-sniffles-a-work-in-progress-report-at-pydatalondon-2016/"&gt;http://ianozsvald.com/2016/05/07/statistically-solving-sneezes-and-sniffles-a-work-in-progress-report-at-pydatalondon-2016/&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Statistically Solving Sneezes and Sniffles Step by Step</title><link href="http://pyvideo.org/pydata-london-2016/ian-ozsvald-giles-weaver-statistically-solving-sneezes-and-sniffles-step-by-step.html" rel="alternate"></link><published>2016-05-11T00:00:00+00:00</published><updated>2016-05-11T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2016-05-11:pydata-london-2016/ian-ozsvald-giles-weaver-statistically-solving-sneezes-and-sniffles-step-by-step.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData London 2016&lt;/p&gt;
&lt;p&gt;Since April 2015 our group has studied the Allergic Rhinitis of a subject with the goal of building a machine learned model that predicts the need for antihistamines. Approximately 30% of the world's population suffers from allergies, we aim to provide a methodology for others to identify the drivers of their own symptoms.&lt;/p&gt;
&lt;p&gt;This is a &amp;quot;citizen science&amp;quot; project, currently focused on one individual and a year's worth of self-reported antihistamine usage, sneezing data and geolocated points. We'll discuss the available external data (including the London Air project's pollution readings, weather, diet, exercise and commute data), exploratory data analysis, our approach to feature engineering from time-series and text sources and our modeling progress.&lt;/p&gt;
&lt;p&gt;The data logging iPhone app and data preparation tools are all open sourced. Python tools discussed include scikit-learn, statsmodels, glueviz, textract and t-sne. We'll also review our distributed working practices.&lt;/p&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="https://speakerdeck.com/ianozsvald/statistically-solving-sniffles-step-by-step-a-work-in-progress"&gt;https://speakerdeck.com/ianozsvald/statistically-solving-sniffles-step-by-step-a-work-in-progress&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Cleaning Confused Collections of Characters</title><link href="http://pyvideo.org/pydata-paris-2015/cleaning-confused-collections-of-characters.html" rel="alternate"></link><published>2015-04-10T00:00:00+00:00</published><updated>2015-04-10T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2015-04-10:pydata-paris-2015/cleaning-confused-collections-of-characters.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Success in data science projects depends upon clean input data. Text
data is often badly encoded, lacks data types and is inconsistent. Aimed
at the intermediate Pythonista I’ll talk about the time saving tools I
use in ModelInsight to clean and normalise my data so you can easily
work on new projects.&lt;/p&gt;
</summary></entry><entry><title>Experiences making CPU-bound tasks run much faster</title><link href="http://pyvideo.org/europython-2011/experiences-making-cpu-bound-tasks-run-much-faste.html" rel="alternate"></link><published>2011-07-18T00:00:00+00:00</published><updated>2011-07-18T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2011-07-18:europython-2011/experiences-making-cpu-bound-tasks-run-much-faste.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Ian Ozsvald - 22 June 2011 in &amp;quot;Training Pizza
Margherita &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;UPDATE - post-event I've created a &lt;a class="reference external" href="http://ianozsvald.com/2011/06/29/high-performance-python-tutorial-v0-1%20-from-my-4-hour-tutorial-at-europython-2011/"&gt;49 page PDF write-
up&lt;/a&gt;
which summarises the 4 hour tutorial&lt;/p&gt;
&lt;p&gt;As a long-time R&amp;amp;D consultant I'm often working to make slow,
experimental code run faster for tasks like physics simulation, flood
modeling and natural language processing. Python allows a smooth
progression from rough-and-ready (but slow) algorithms through to finely
tuned tasks that efficiently use as much CPU power as you can bring to
bear. Speed-ups of 10-500* can be expected for the Mandelbrot code
we'll use.&lt;/p&gt;
&lt;p&gt;In this talk I'll cover a set of libraries that make CPU-bound tasks run
much faster. We'll begin with a look at profiling using RunSnakeRun and
line_profiler to identify our bottleneck. We'll take a look at slow
algorithms in Python and how they can run faster using numpy and
numexpr.&lt;/p&gt;
&lt;p&gt;Next we'll cover the use of multiprocessing to utilise multiple CPU
cores along with Cython or ShedSkin to easily use C code in a friendly
Python wrapper. Multiprocessing on a quad-core system can often provide
a 4* speed-up for the right tasks. Next parallelpython will let us run
our code on a network of machines.&lt;/p&gt;
&lt;p&gt;Finally we'll look at pyCUDA to utilise an NVIDIA GPU. CUDA can give the
best improvements for mathematical problems (over 100* on the right
tasks) but works on a narrower set of problems.&lt;/p&gt;
&lt;p&gt;How it'll work: The tutorial will be hands on, you'll be converting
example files from normal Python to faster variants using the tools
below. All of it is optional, you'll get the most benefit by having
everything installed. We'll work in groups and open discussion is
encouraged.&lt;/p&gt;
&lt;p&gt;NOTE - you are expected to have all these tools installed &lt;em&gt;before&lt;/em&gt; the
tutorial (if you don't, you might find it hard to follow what's going
on!).&lt;/p&gt;
&lt;p&gt;I'll be using Python 2.7.1 on a Macbook (Snow Leopard). All of these
tools run on Windows and Linux, as long as your versions are fairly
recent everything should run just fine.&lt;/p&gt;
&lt;p&gt;My versions (roughly ordered by importance):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python 2.7.1&lt;/li&gt;
&lt;li&gt;RunSnakeRun 2.0.1b6 (with wxPython 2.8.12.0 Unicode)&lt;/li&gt;
&lt;li&gt;line_profiler (1.0b2)&lt;/li&gt;
&lt;li&gt;Cython 0.14.1&lt;/li&gt;
&lt;li&gt;ShedSkin 0.7.1&lt;/li&gt;
&lt;li&gt;numpy 1.5.1&lt;/li&gt;
&lt;li&gt;numexpr 1.4.2&lt;/li&gt;
&lt;li&gt;ParallelPython 1.6.1&lt;/li&gt;
&lt;li&gt;pyCUDA HEAD from git as of 14th June 2011 (with CUDA 4.0 drivers)&lt;/li&gt;
&lt;li&gt;PyPy 1.5&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some background reading:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://ianozsvald.com/2010/07/14/22937-faster-python-math-using-pycuda/"&gt;http://ianozsvald.com/2010/07/14/22937-faster-python-math-using-pycuda/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://ianozsvald.com/2008/11/17/making-python-math-196-faster-with-shedskin/"&gt;http://ianozsvald.com/2008/11/17/making-python-math-196-faster-with-shedskin/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="cython"></category><category term="git"></category><category term="multiprocessing"></category><category term="network"></category><category term="numpy"></category><category term="nvidia"></category><category term="profiling"></category><category term="pycuda"></category><category term="runsnakerun"></category><category term="tutorial"></category><category term="windows"></category><category term="wxpython"></category></entry><entry><title>High Performance Python I</title><link href="http://pyvideo.org/pycon-us-2012/high-performance-python-i.html" rel="alternate"></link><published>2012-03-08T00:00:00+00:00</published><updated>2012-03-08T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2012-03-08:pycon-us-2012/high-performance-python-i.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;At EuroPython 2011 I ran a very hands-on tutorial for High Performance
Python techniques. This updated tutorial will cover profiling, PyPy,
Cython, numpy, NumExpr, ShedSkin, multiprocessing, ParallelPython and
pyCUDA. Here's a 55 page PDF write-up of the EuroPython material:
&lt;a class="reference external" href="http://ianozsvald.com/2011/07/25"&gt;http://ianozsvald.com/2011/07/25&lt;/a&gt;
/high-performance-python-tutorial-v0-2-from-europython-2011/&lt;/p&gt;
</summary></entry><entry><title>Applied Parallel Computing with Python</title><link href="http://pyvideo.org/pycon-us-2013/applied-parallel-computing-with-python.html" rel="alternate"></link><published>2013-03-14T00:00:00+00:00</published><updated>2013-03-14T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2013-03-14:pycon-us-2013/applied-parallel-computing-with-python.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;In this tutorial we shall review three different and distinct approaches
to parallel computing which can be used to solve problems in all manner
of domains, including machine learning, natural language processing,
finance, and computer vision. The first two approaches to be reviewed
will be embarrassingly parallel in nature while the third approach will
leverage fine-grain parallelism.&lt;/p&gt;
</summary><category term="tutorial"></category></entry></feed>