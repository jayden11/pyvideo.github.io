<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>http://pyvideo.org/</link><description></description><lastBuildDate>Fri, 07 Oct 2016 00:00:00 +0000</lastBuildDate><item><title>How I learnt to stop worrying and love Boost.Python</title><link>http://pyvideo.org/pycon-za-2015/how-i-learnt-to-stop-worrying-and-love-boostpyth.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Zen of Python dictates that there should be one - and preferably
only one - obvious way to do something. However, when it comes to
interoperation with C and C++, there is a multitude of options: the
Python C API, Boost.Python, ctypes, cffi, Cython. I will describe my
quest to find the &lt;strong&gt;holy grail&lt;/strong&gt;&lt;sup&gt;W&lt;/sup&gt;W &lt;strong&gt;right interface&lt;/strong&gt; for a
high-performance networking library.&lt;/p&gt;
&lt;p&gt;The talk is largely a case study in applying Boost.Python, and will look
at some issues such as the Global Interpreter Lock, handling
KeyboardInterrupt cleanly, and managing object lifetime. I will briefly
mention some of the alternative tools to explain why I settled on
Boost.Python. It is not a complete Boost.Python tutorial, but rather
aims to give a sense of the flavour and show how it's used in a real
application.&lt;/p&gt;
&lt;p&gt;For obvious reasons, this talk will have a lot of C++ code in it, and
some familiarity with C++ will be useful.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bruce Merry</dc:creator><pubDate>Fri, 02 Oct 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-10-02:pycon-za-2015/how-i-learnt-to-stop-worrying-and-love-boostpyth.html</guid><category>Room 215</category></item><item><title>Thursday Lightning Talks</title><link>http://pyvideo.org/pycon-za-2015/thursday-lightning-talks.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://youtu.be/DiaE9GCJ0nM?t=0h0m0s"&gt;(0:00:00)&lt;/a&gt; &lt;strong&gt;Racy interrupt handling&lt;/strong&gt; by Bruce Merry&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://youtu.be/DiaE9GCJ0nM?t=0h6m0s"&gt;(0:06:00)&lt;/a&gt; &lt;strong&gt;Vulture in Python&lt;/strong&gt; by Philip Sterne&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://youtu.be/DiaE9GCJ0nM?t=0h11m9s"&gt;(0:11:09)&lt;/a&gt; &lt;strong&gt;Edx&lt;/strong&gt; by Carl Dawson&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://youtu.be/DiaE9GCJ0nM?t=0h17m39s"&gt;(0:17:39)&lt;/a&gt; &lt;strong&gt;AST linting&lt;/strong&gt; by Bryn Divey&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://youtu.be/DiaE9GCJ0nM?t=0h24m33s"&gt;(0:24:33)&lt;/a&gt; &lt;strong&gt;Numpy in Anger!&lt;/strong&gt; by Laura Richter&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://youtu.be/DiaE9GCJ0nM?t=0h29m28s"&gt;(0:29:28)&lt;/a&gt; &lt;strong&gt;How to screw up loading CSVs in Python&lt;/strong&gt; by James Saunders&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://youtu.be/DiaE9GCJ0nM?t=0h33m34s"&gt;(0:33:34)&lt;/a&gt; &lt;strong&gt;PyQuery&lt;/strong&gt; by Nicholas Spagnoletti&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://youtu.be/DiaE9GCJ0nM?t=0h37m27s"&gt;(0:37:27)&lt;/a&gt; &lt;strong&gt;Debian Python moves kicking and screaming to Git&lt;/strong&gt; by Stefano Rivera&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bruce Merry</dc:creator><pubDate>Thu, 01 Oct 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-10-01:pycon-za-2015/thursday-lightning-talks.html</guid><category>Room 215</category></item><item><title>Juggling GPU tasks with asyncio</title><link>http://pyvideo.org/pycon-za-2016/juggling-gpu-tasks-with-asyncio.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Getting peak performance with a GPU requires juggling concurrent tasks:
copying data to the GPU, processing data, and copying results back off
can all happen in parallel. In a distributed system, data arrives from
the network and results are sent back over the network. Python's asyncio
module is a great way to manage all these concurrent tasks while
avoiding many of the hazards of multiple threads.&lt;/p&gt;
&lt;p&gt;This talk will describe how I've used asyncio (actually trollius, the
Python 2 backport) to make this all work for GPU-accelerated real-time
processing in the MeerKAT radio telescope. I'll cover some helper
classes I've written for ensuring that operations happen in the right
order, and talk about how changing from a threaded model to trollius has
simplified the code.&lt;/p&gt;
&lt;p&gt;No experience with GPU programming or asyncio/trollius is required or
expected. Some prior exposure to event-driven programming or coroutines
in Python would be useful.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bruce Merry</dc:creator><pubDate>Fri, 07 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-07:pycon-za-2016/juggling-gpu-tasks-with-asyncio.html</guid></item></channel></rss>