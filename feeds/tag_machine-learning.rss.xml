<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>http://pyvideo.org/</link><description></description><lastBuildDate>Fri, 30 Dec 2016 00:00:00 +0000</lastBuildDate><item><title>Machine Learning for Absolute beginners</title><link>http://pyvideo.org/pydx-2016/machine-learning-for-absolute-beginners.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyDX tutorial by Hailey Buckingham&lt;/p&gt;
&lt;p&gt;You should come to this tutorial if you are interested in finding out what machine learning is all about, and how to begin using it in your python projects. Attendees should have some experience with python, and be familiar with some algebra but you don't have to be a guru at either one!&lt;/p&gt;
&lt;p&gt;You will come away with an introductory understanding of what machine learning is and the problems it can be used to solve, as well as some basic steps for setting up basic machine learning tools in your python projects.&lt;/p&gt;
&lt;p&gt;We'll be using SciPy and Scikit-learn to walk through some basic machine learning tasks on several small data sets.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Hailey Buckingham</dc:creator><pubDate>Fri, 30 Dec 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-12-30:pydx-2016/machine-learning-for-absolute-beginners.html</guid><category>machine learning</category></item><item><title>Machine Learning Techniques for Class Imbalances &amp; Adversaries</title><link>http://pyvideo.org/pydata-dc-2016/machine-learning-techniques-for-class-imbalances-adversaries.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;There are many areas of applied Machine Learning which require models optimized for rare occurrences (i.e. class imbalance), as well as users actively attempting to subvert the system (i.e. adversaries).&lt;/p&gt;
&lt;p&gt;This talk will guide the audience through multiple published techniques which specifically attempt to address these issues.&lt;/p&gt;
&lt;p&gt;The Data Innovation Lab at Capital One has explored more advanced modeling techniques for class imbalance &amp;amp; adversarial actors. Our use case has allowed us to survey the many related fields which deal with these issues, and attempt many of the suggested modeling techniques. Additionally, we have introduce a few novel variations of our own.&lt;/p&gt;
&lt;p&gt;This talk will provide an introduction to the problem space, a brief overview of the modeling frameworks we've chosen to work with, a brief overview of our approaches, a discussion of lessons learned, and our proposed future work.&lt;/p&gt;
&lt;p&gt;The approaches discussed will include ensemble models, deep learning, genetic algorithms, outlier detection via dimensionally reduction (PCA and neural network auto-encoders), time-decay weighting, and Synthetic Minority Over-sampling Technique (SMOTE sampling).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brendan Herger</dc:creator><pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-09:pydata-dc-2016/machine-learning-techniques-for-class-imbalances-adversaries.html</guid><category>class</category><category>learning</category><category>machine learning</category></item><item><title>Visual diagnostics for more informed machine learning</title><link>http://pyvideo.org/pydata-dc-2016/visual-diagnostics-for-more-informed-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Visualization has a critical role to play throughout the analytic process. Where static outputs and tabular data can obscure patterns, human visual analysis can open up insights that lead to more robust data products. For Python programmers who dabble in machine learning, visual diagnostics are a must-have for effective feature analysis, model selection, and parameter tuning.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rebecca Bilbro</dc:creator><pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-09:pydata-dc-2016/visual-diagnostics-for-more-informed-machine-learning.html</guid><category>learning</category><category>machine learning</category></item><item><title>Building Serverless Machine Learning Models in the Cloud</title><link>http://pyvideo.org/pydata-dc-2016/building-serverless-machine-learning-models-in-the-cloud.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;You’ll learn how to efficiently design and train machine learning models in Python and deploy them to the cloud. This process reduces the development &amp;amp; operational efforts required to make your prototypes production-ready.&lt;/p&gt;
&lt;p&gt;We will describe the main challenges faced by data scientists involved in deploying machine learning models into real production environments with specific references, examples of Python libraries, and multi-model systems requiring advanced features such as A/B testing and high scalability &amp;amp; availability.&lt;/p&gt;
&lt;p&gt;While discussing the advantages and limitations of multiple deployment strategies in the cloud, we will focus on serverless computing (i.e. AWS Lambda) as a solution for simplifying your development &amp;amp; deployment workflows.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alex Casalboni</dc:creator><pubDate>Sat, 08 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-08:pydata-dc-2016/building-serverless-machine-learning-models-in-the-cloud.html</guid><category>Cloud</category><category>learning</category><category>machine learning</category><category>models</category><category>serverless</category></item><item><title>Beyond Sentiment Emotion Mining with Python and machine learning</title><link>http://pyvideo.org/pydata-dc-2016/beyond-sentiment-emotion-mining-with-python-and-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Learn how to extract emotional content from textual data - and how to build a sentiment analysis tool that does not suck.&lt;/p&gt;
&lt;p&gt;Typical sentiment analysis tries to map the entire rich and varied world of human emotions into &amp;quot;good&amp;quot; vs &amp;quot;bad&amp;quot;. In this tutorial, we use the characters of &amp;quot;Inside Out&amp;quot; and machine learning to build a nuanced model of human emotions -- and put it in production!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Max Tsvetovat</dc:creator><pubDate>Fri, 07 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-07:pydata-dc-2016/beyond-sentiment-emotion-mining-with-python-and-machine-learning.html</guid><category>learning</category><category>machine learning</category></item><item><title>Machine Learning with Text in scikit learn</title><link>http://pyvideo.org/pydata-dc-2016/machine-learning-with-text-in-scikit-learn.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/justmarkham/pydata-dc-2016-tutorial"&gt;https://github.com/justmarkham/pydata-dc-2016-tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Although numeric data is easy to work with in Python, most knowledge created by humans is actually raw, unstructured text. By learning how to transform text into data that is usable by machine learning models, you drastically increase the amount of data that your models can learn from. In this tutorial, we'll build and evaluate predictive models from real-world text using scikit-learn.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Fri, 07 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-07:pydata-dc-2016/machine-learning-with-text-in-scikit-learn.html</guid><category>learning</category><category>machine learning</category><category>scikit</category></item><item><title>Genotype Phenotype Modelling with Python and Machine Learning</title><link>http://pyvideo.org/pydata-chicago-2016/genotype-phenotype-modelling-with-python-and-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Genotype-phenotype studies are done for predicting traits such as whether someone will go bald or have a particular disease given their only genome. We look at how Python libraries such as scikit-learn and keras have made it easier to develop these statistical models. We describe a pipeline to predict antimicrobial resistance in bacteria and elaborate on challenges when working with genomic data.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mat Kallada</dc:creator><pubDate>Sun, 28 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-28:pydata-chicago-2016/genotype-phenotype-modelling-with-python-and-machine-learning.html</guid><category>learning</category><category>machine learning</category></item><item><title>Machine learning techniques for data cleaning</title><link>http://pyvideo.org/pydata-chicago-2016/machine-learning-techniques-for-data-cleaning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1k42esoWoc_WezfPfQ5vxbHTsuFOvAshEusD-GFCElTQ/edit#slide=id.g166bf446d8_1_12"&gt;https://docs.google.com/presentation/d/1k42esoWoc_WezfPfQ5vxbHTsuFOvAshEusD-GFCElTQ/edit#slide=id.g166bf446d8_1_12&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Often, the most interesting datasets - data about people and organizations - are the messiest and most difficult to analyze. When data comes from multiple sources, or when data is entered manually, variation &amp;amp; ambiguity are inevitable. Learn about ways to infer structure and relationships in messy data, using open source Python libraries.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Cathy Deng</dc:creator><pubDate>Sun, 28 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-28:pydata-chicago-2016/machine-learning-techniques-for-data-cleaning.html</guid><category>Data</category><category>learning</category><category>machine learning</category></item><item><title>Deploying Machine Learning using sklearn pipelines</title><link>http://pyvideo.org/pydata-chicago-2016/deploying-machine-learning-using-sklearn-pipelines.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Sklearn pipeline objects provide an framework that simplifies the lifecycle of data science models. This talk will cover the how and why of encoding feature engineering, estimators, and model ensembles in a single deployable object.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Goetsch</dc:creator><pubDate>Sat, 27 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-27:pydata-chicago-2016/deploying-machine-learning-using-sklearn-pipelines.html</guid><category>deploying</category><category>learning</category><category>machine learning</category><category>sklearn</category></item><item><title>Learning scikit learn - An Introduction to Machine Learning in Python</title><link>http://pyvideo.org/pydata-chicago-2016/learning-scikit-learn-an-introduction-to-machine-learning-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;This tutorial provides you with a comprehensive introduction to machine learning in Python using the popular scikit-learn library. We will learn how to tackle common problems in predictive modeling and clustering analysis that can be used in real-world problems, in business and in research applications. And we will implement certain algorithms as scratch as well, to internalize the inner workings&lt;/p&gt;
&lt;p&gt;This tutorial will teach you the basics of scikit-learn. We will learn how to leverage powerful algorithms from the two main domains of machine learning: supervised and unsupervised learning. In this talk, I will give you a brief overview of the basic concepts of classification and regression analysis, how to build powerful predictive models from labeled data. Furthermore, we will go over the basics of clustering analysis to discover hidden structures in unlabeled data. Although it's not a requirement for attending this tutorial, I highly recommend you to check out the accompanying GitHub repository at &lt;a class="reference external" href="https://github.com/rasbt/pydata-chicago2016-ml-tutorial"&gt;https://github.com/rasbt/pydata-chicago2016-ml-tutorial&lt;/a&gt; 1-2 days before the tutorial. During the session, we will not only talk about scikit-learn, but we will also go over some live code examples and code simple machine-learning algorithms from scratch to get the knack of scikit-learn's API.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sebastian Raschka</dc:creator><pubDate>Fri, 26 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-26:pydata-chicago-2016/learning-scikit-learn-an-introduction-to-machine-learning-in-python.html</guid><category>learning</category><category>machine learning</category><category>scikit</category></item><item><title>How do I create dummy variables in pandas?</title><link>http://pyvideo.org/data-school/pandas-24-dummy-variables.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you want to include a categorical feature in your machine learning model, one common solution is to create dummy variables. In this video, I'll demonstrate three different ways you can create dummy variables from your existing DataFrame columns. I'll also show you a trick for simplifying your code that was introduced in pandas 0.18.&lt;/p&gt;
&lt;p&gt;This is video 24 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 12 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-12:data-school/pandas-24-dummy-variables.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>machine learning</category></item><item><title>How do I use pandas with scikit-learn to create Kaggle submissions?</title><link>http://pyvideo.org/data-school/pandas-22-prepare-for-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you been using scikit-learn for machine learning, and wondering whether pandas could help you to prepare your data and export your predictions? In this video, I'll demonstrate the simplest way to integrate pandas into your machine learning workflow, and will create a submission for Kaggle's Titanic competition in just a few lines of code!&lt;/p&gt;
&lt;p&gt;This is video 22 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 28 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-28:data-school/pandas-22-prepare-for-machine-learning.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>scikit-learn</category><category>machine learning</category></item><item><title>How to evaluate a classifier in scikit-learn</title><link>http://pyvideo.org/data-school/scikit-learn-09-evaluating-classification-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, you'll learn how to properly evaluate a classification model using a variety of common tools and metrics, as well as how to adjust the performance of a classifier to best match your business objectives. I'll start by demonstrating the weaknesses of classification accuracy as an evaluation metric. I'll then discuss the confusion matrix, the ROC curve and AUC, and metrics such as sensitivity, specificity, and precision. By the end of the video, you will have a solid foundation for intelligently evaluating your own classification model.&lt;/p&gt;
&lt;p&gt;This is the ninth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Fri, 23 Oct 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-10-23:data-school/scikit-learn-09-evaluating-classification-models.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>model evaluation</category><category>classification</category><category>confusion matrix</category><category>ROC curve</category><category>AUC</category></item><item><title>How to find the best model parameters in scikit-learn</title><link>http://pyvideo.org/data-school/scikit-learn-08-parameter-tuning-with-grid-search.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, you'll learn how to efficiently search for the optimal tuning parameters (or &amp;quot;hyperparameters&amp;quot;) for your machine learning model in order to maximize its performance. I'll start by demonstrating an exhaustive &amp;quot;grid search&amp;quot; process using scikit-learn's GridSearchCV class, and then I'll compare it with RandomizedSearchCV, which can often achieve similar results in far less time.&lt;/p&gt;
&lt;p&gt;This is the eighth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Wed, 15 Jul 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-07-15:data-school/scikit-learn-08-parameter-tuning-with-grid-search.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>cross-validation</category><category>model evaluation</category><category>parameter tuning</category><category>grid search</category></item><item><title>Selecting the best model in scikit-learn using cross-validation</title><link>http://pyvideo.org/data-school/scikit-learn-07-model-evaluation-with-cross-validation.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, we'll learn about K-fold cross-validation and how it can be used for selecting optimal tuning parameters, choosing between models, and selecting features. We'll compare cross-validation with the train/test split procedure, and we'll also discuss some variations of cross-validation that can result in more accurate estimates of model performance.&lt;/p&gt;
&lt;p&gt;This is the seventh video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Sun, 28 Jun 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-06-28:data-school/scikit-learn-07-model-evaluation-with-cross-validation.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>cross-validation</category><category>model evaluation</category><category>feature selection</category><category>parameter tuning</category></item><item><title>Data science in Python: pandas, seaborn, scikit-learn</title><link>http://pyvideo.org/data-school/scikit-learn-06-data-science-pipeline.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, we'll cover the data science pipeline from data ingestion (with pandas) to data visualization (with seaborn) to machine learning (with scikit-learn). We'll learn how to train and interpret a linear regression model, and then compare three possible evaluation metrics for regression problems. Finally, we'll apply the train/test split procedure to decide which features to include in our model.&lt;/p&gt;
&lt;p&gt;This is the sixth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 28 May 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-05-28:data-school/scikit-learn-06-data-science-pipeline.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>pandas</category><category>seaborn</category><category>linear regression</category><category>model evaluation</category><category>feature selection</category><category>visualization</category></item><item><title>Comparing machine learning models in scikit-learn</title><link>http://pyvideo.org/data-school/scikit-learn-05-comparing-machine-learning-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We've learned how to train different machine learning models and make predictions, but how do we actually choose which model is &amp;quot;best&amp;quot;? We'll cover the train/test split process for model evaluation, which allows you to avoid &amp;quot;overfitting&amp;quot; by estimating how well a model is likely to perform on new data. We'll use that same process to locate optimal tuning parameters for a KNN model, and then we'll re-train our model so that it's ready to make real predictions.&lt;/p&gt;
&lt;p&gt;This is the fifth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 14 May 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-05-14:data-school/scikit-learn-05-comparing-machine-learning-models.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>model evaluation</category><category>overfitting</category></item><item><title>Training a machine learning model with scikit-learn</title><link>http://pyvideo.org/data-school/scikit-learn-04-training-a-machine-learning-model.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Now that we're familiar with the famous iris dataset, let's actually use a classification model in scikit-learn to predict the species of an iris! We'll learn how the K-nearest neighbors (KNN) model works, and then walk through the four steps for model training and prediction in scikit-learn. Finally, we'll see how easy it is to try out a different classification model, namely logistic regression.&lt;/p&gt;
&lt;p&gt;This is the fourth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Wed, 29 Apr 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-04-29:data-school/scikit-learn-04-training-a-machine-learning-model.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>classification</category><category>KNN</category></item><item><title>Getting started in scikit-learn with the famous iris dataset</title><link>http://pyvideo.org/data-school/scikit-learn-03-getting-started-with-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Now that we've set up Python for machine learning, let's get started by loading an example dataset into scikit-learn! We'll explore the famous &amp;quot;iris&amp;quot; dataset, learn some important machine learning terminology, and discuss the four key requirements for working with data in scikit-learn.&lt;/p&gt;
&lt;p&gt;This is the third video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 21 Apr 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-04-21:data-school/scikit-learn-03-getting-started-with-machine-learning.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>NumPy</category></item><item><title>Setting up Python for machine learning: scikit-learn and IPython Notebook</title><link>http://pyvideo.org/data-school/scikit-learn-02-machine-learning-setup.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Want to get started with machine learning in Python? I'll discuss the pros and cons of the scikit-learn library, show how to install my preferred Python distribution, and demonstrate the basic functionality of the IPython Notebook. If you don't yet know any Python, I'll also provide four recommended resources for learning Python.&lt;/p&gt;
&lt;p&gt;This is the second video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Wed, 15 Apr 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-04-15:data-school/scikit-learn-02-machine-learning-setup.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>IPython notebook</category><category>Jupyter notebook</category></item><item><title>What is machine learning, and how does it work?</title><link>http://pyvideo.org/data-school/scikit-learn-01-what-is-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you heard of &amp;quot;machine learning&amp;quot;, and you're trying to figure out exactly what that means? I'll give you my definition, provide some examples of machine learning, and explain at a high level how machine learning &amp;quot;works&amp;quot;.&lt;/p&gt;
&lt;p&gt;This is the first video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 07 Apr 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-04-07:data-school/scikit-learn-01-what-is-machine-learning.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>supervised learning</category><category>unsupervised learning</category></item><item><title>Fighting the Flu with Machine Learning</title><link>http://pyvideo.org/pygotham-2016/fighting-the-flu-with-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Everyone despises falling sick. In this talk, I will present how I used Python and machine learning to predict future sequences of the flu. My Random Forests model learns patterns in how the flu mutates from previous flu seasons, and creates decision trees based on those inferences. I will also cover how using a library (scikit-learn) was much easier and accurate than creating a Random Forests Classifier.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rohan Koodli</dc:creator><pubDate>Sat, 16 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-16:pygotham-2016/fighting-the-flu-with-machine-learning.html</guid><category>Machine Learning</category></item><item><title>Build Data Apps by Deploying ML Models as API Services</title><link>http://pyvideo.org/pydata-san-francisco-2016/build-data-apps-by-deploying-ml-models-as-api-services.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData SF 2016
Ramesh Sampath | Build Data Apps by Deploying ML Models as API Services&lt;/p&gt;
&lt;p&gt;As data scientists, we love building models using IPython Notebooks / Scikit-Learn / Pandas eco-system. But integrating these models with an web app can be a challenge. In this tutorial, we will take our machine learning models and make them available as APIs for use by Web and Mobile Apps. We will also build a simple webapp that uses our prediction service.&lt;/p&gt;
&lt;p&gt;Deploy your ML Models as a Service&lt;/p&gt;
&lt;p&gt;In this talk, we will learn one way to take our Machine Learning models and make them available as a Prediction Service. We will work through the following steps.&lt;/p&gt;
&lt;p&gt;Create a Simple Machine learning Model using Scikit-Learn / Pandas
Pickle the model
Using Tornado Web App, Make this model available as an API Service
Build an Web App that uses this deployed Model
Add Authentication to our Prediction API
Optionally, add Redis to Cache Prediction Results
Deploy the model in the Cloud (AWS)
Please have Anaconda or Miniconda installed on your local machine. I will mostly be using Python 3.5, but Python 2.7 should be fine as well.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ramesh Sampath</dc:creator><pubDate>Wed, 24 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-24:pydata-san-francisco-2016/build-data-apps-by-deploying-ml-models-as-api-services.html</guid><category>tutorial</category><category>machine learning</category><category>scikit-learn</category><category>pandas</category><category>tornado</category></item><item><title>Setting up predictive analytics services with Palladium</title><link>http://pyvideo.org/pydata-berlin-2016/setting-up-predictive-analytics-services-with-palladium.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;We will introduce Palladium, an open source framework for setting up predictive analytics services. It supports tasks like fitting, evaluating, storing, and distributing (predictive) models. Core ML processes are compatible with scikit-learn and a large number of scikit-learn’s features can be used. Besides the use of Palladium we will also show how to use it with Docker and Mesos / Marathon.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In this talk, we will introduce Palladium, an open source framework for easily setting up predictive analytics services (&lt;a class="reference external" href="https://github.com/ottogroup/palladium"&gt;https://github.com/ottogroup/palladium&lt;/a&gt;). It supports tasks like fitting, evaluating, storing, distributing, and updating (predictive) models. Core machine learning processes are compatible with the open source machine learning library scikit-learn and thus, a large number of scikit-learn’s features can be used with Palladium. Although being implemented in Python, Palladium provides support for other languages and is shipped with examples how to integrate and expose R and Julia models. For an efficient deployment of services based on Palladium, a script to create Docker images automatically is provided. This talk will cover the use of Palladium including an example where a simple classification service is set up. We will also show how Docker and Mesos / Marathon can be used to deploy and scale Palladium-based services. Having basic knowledge about Machine Learning and/or scikit-learn would be an advantage when attending this talk.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andreas Lattner</dc:creator><pubDate>Tue, 07 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-07:pydata-berlin-2016/setting-up-predictive-analytics-services-with-palladium.html</guid><category>palladium</category><category>scikit-learn</category><category>docker</category><category>mesos</category><category>marathon</category><category>machine learning</category></item><item><title>Introducción a Machine Learning con Python</title><link>http://pyvideo.org/pyday-galicia-2016/introduccion-a-machine-learning-con-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Charla introductoria a Machine Learning con Python:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introducción: Definición, terminología y casos de uso.&lt;/li&gt;
&lt;li&gt;Herramientas: Numpy, SciPy, Pandas, Scikit-learn y Anaconda&lt;/li&gt;
&lt;li&gt;Regresión lineales&lt;/li&gt;
&lt;li&gt;Clustering: kmeans, elegir número de clusters&lt;/li&gt;
&lt;li&gt;Decision tree: Arbol de decisiones, Overfitting&lt;/li&gt;
&lt;li&gt;KNeighbors: Funcionamiento de KNeighbors, Acierto vs. nº vecinos, Nunca pruebes un modelo con los mismos datos que usaste para entrenarlo.&lt;/li&gt;
&lt;li&gt;Feature engineering: Titanic dataset&lt;/li&gt;
&lt;li&gt;Metricas: Precision &amp;amp; Recall. CKD (Chronic Kidney Disease) dataset&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Xurxo Fresco</dc:creator><pubDate>Sat, 17 Sep 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-09-17:pyday-galicia-2016/introduccion-a-machine-learning-con-python.html</guid><category>pyday</category><category>machine learning</category><category>kmeans</category><category>kneighbors</category><category>decision tree</category></item><item><title>Por qué Charles Xavier debe cambiar Cerebro por Python</title><link>http://pyvideo.org/pycon-es-2014/por-que-charles-xavier-debe-cambiar-cerebro-por-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Los buenos de Marvel han liberado su API, ¿qué quiere decir esto? ¡Un montón de datos para jugar!&lt;/p&gt;
&lt;p&gt;La premisa que queremos estudiar mediante el análisis de los datos disponibles a través de la API de Marvel es la variedad de personajes femeninos y de personajes de minorías culturales y raciales (en occidente) que hay en el mundo Marvel así como los roles en los que están representados más frecuentemente. ¿De qué color dirías que tiene el pelo el personaje típico de Marvel? ¿Y cuál es su nacionalidad?&lt;/p&gt;
&lt;p&gt;El objetivo de la charla es enseñar las distintas herramientas de las que disponemos los científicos para el análisis de datos. Usando ipython Notebook veremos como cargar datos y extraer información de ellos usando pandas, cómo dibujar gráficas con matplotlib.&lt;/p&gt;
&lt;p&gt;Además aplicaremos Machine Learning para distinguir clases (iris, spam,...) aplicado a la muestra de personajes de Marvel que hay disponibles a través de la citada API, para ello utilizaremos el toolkit scikit-learn.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://nbviewer.ipython.org/github/mshopper/aurora/blob/master/Aurora.ipynb"&gt;http://nbviewer.ipython.org/github/mshopper/aurora/blob/master/Aurora.ipynb&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mayte Gimenez</dc:creator><pubDate>Mon, 06 Apr 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-04-06:pycon-es-2014/por-que-charles-xavier-debe-cambiar-cerebro-por-python.html</guid><category>marvel api</category><category>ipython</category><category>notebook</category><category>machine learning</category></item><item><title>PyGotham 2011: Machine Learning for Web Developers</title><link>http://pyvideo.org/pygotham-2011/pygotham-2011--machine-learning-for-web-developer.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Machine learning deals with a class of algorithms which improve and
evolve as they process more data. It has wide-ranging applications in
recommendations, search, spam/fraud detection, facial recognition and
other areas. The algorithms themselves will be covered but the real
focus of this class is on how to use said algorithms in the web
applications we work on every day. I&amp;amp;aposll try to keep the math and
notation relatively light. Most of the algorithms you&amp;amp;aposll need to get
started with machine learning are implemented for you in the various
libraries. They comprise the &amp;quot;science&amp;quot; of machine learning and I hope
you will decide to learn it, but mastering that material is a
significant commitment of your time and mental energy (and has some
additional prerequisites including a strong understanding of linear
algebra). This class will focus on the &amp;quot;art&amp;quot; of machine learning, how to
think about machine learning algorithms and integrate them into your web
application.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Al Barrentine</dc:creator><pubDate>Mon, 01 Jan 1990 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,1990-01-01:pygotham-2011/pygotham-2011--machine-learning-for-web-developer.html</guid><category>machine learning</category><category>pygotham</category><category>pygotham2011</category><category>web</category></item><item><title>Beginner's Guide to Machine Learning Competitions</title><link>http://pyvideo.org/pytexas-2015/beginners-guide-to-machine-learning-competitions.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This tutorial will offer a hands-on introduction to machine learning and
the process of applying these concepts in a Kaggle competition. We will
introduce attendees to machine learning concepts, examples and flows,
while building up their skills to solve an actual problem. At the end of
the tutorial attendees will be familiar with a real data science flow:
feature preparation, modeling, optimization and validation.&lt;/p&gt;
&lt;p&gt;Packages used in the tutorial will include: IPython notebook,
scikit-learn, pandas and NLTK. We’ll use IPython notebook for
interactive exploration and visualization, in order to gain a basic
understanding of what’s in the data. From there, we’ll extract features
and train a model using scikit-learn. This will bring us to our first
submission. We’ll then learn how to structure the problem for offline
evaluation and use scikit-learn’s clean model API to train many models
simultaneously and perform feature selection and hyperparameter
optimization.&lt;/p&gt;
&lt;p&gt;At the end of session, attendees will have time to work on their own to
improve their models and make multiple submissions to get to the top of
the leaderboard, just like in a real competition. Hopefully attendees
will not only leave the tutorial having learned the core data science
concepts and flow, but also having had a great time doing it.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Christine Doig</dc:creator><pubDate>Fri, 09 Oct 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-10-09:pytexas-2015/beginners-guide-to-machine-learning-competitions.html</guid><category>tutorial</category><category>machine learning</category><category>nltk</category><category>pandas</category><category>scikit-learn</category><category>ipython</category></item><item><title>All-by-all learning of protein complexes from mass spectrometry data</title><link>http://pyvideo.org/scipy-2013/all-by-all-learning-of-protein-complexes-from-mas-.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Authors: Blake Borgeson, Center for Systems and Synthetic Biology,
University of Texas at Austin; Cuihong Wa&lt;/p&gt;
&lt;p&gt;Track: Bioinformatics&lt;/p&gt;
&lt;p&gt;Despite our knowledge that the vast majority of life's processes at a
cellular level are carried out by complexes of multiple proteins,
knowledge of all the complexes formed in a cell and their members is a
distant goal. By using a new approach first applied to human cell lines
by collaborators Havugimana and Hart, et al, consisting of 1) subjecting
biological samples to many levels of many types of fractionations, 2)
using mass spectrometry to quantify protein levels in each fraction, and
3) processing the data through a machine learning pipeline, we are able
to seek complexes using a high-throughput all-by-all approach. By
incorporating additional functional genomic information into our
learning process, we are able to reconstruct maps of complexes that
rival in quality and far surpass in coverage those generated with
previously-used, much more labor-intensive methods such as affinity
purification followed by mass spectrometry, or AP-MS. Here, using 6,000
mass spectrometry experiments from more than 60 fractionated biological
samples from human, mouse, sea urchin, fly and worm, we predict with
high confidence hundreds (~500) of expected and putative novel conserved
complexes. IPython, SciPy, and scikit-learn are the foundational tools
used to handle data integration and machine learning, and an integrated
python environment for this work has been critical to the speed of
progress.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Blake Borgeson</dc:creator><pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-07-01:scipy-2013/all-by-all-learning-of-protein-complexes-from-mas-.html</guid><category>bioinformatics</category><category>machine learning</category></item><item><title>Detection and characterization of interactions of genetic risk factors</title><link>http://pyvideo.org/scipy-2013/detection-and-characterization-of-interactions-of-.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Much attention has been focused on the application of machine learning
approaches to detection of gene interactions. Our method is based upon
training a supervised learning algorithm to detect disease, and then
quantifying the effect on prediction accuracy when alleles of two or
more genes are perturbed to unmutated in patterns so as to reveal and
characterize gene interactions.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Detection and characterization of interactions of genetic risk factors
in disease&lt;/p&gt;
&lt;p&gt;Authors: Francis-Lyon, Patricia, University of San Francisco; Belvadi,
Shashank, University of San Francisco; Wang, Lin, University of San
Francisco&lt;/p&gt;
&lt;p&gt;Track: Bioinformatics&lt;/p&gt;
&lt;p&gt;It is well known that two or more genes can interact so as to enhance or
suppress incidence of disease, such that the observed phenotype differs
from when the genes act independently. The effect of a gene allele at
one locus can mask or modify the effect of alleles at one or more other
loci. Discovery and characterization of such gene interactions is
pursued as a valuable aid in early diagnosis and treatment of disease.
Also it is hoped that the characterization of such interactions will
shed light on biological and biochemical pathways that are involved in a
specific disease, leading to new therapeutic treatments.&lt;/p&gt;
&lt;p&gt;Much attention has been focused on the application of machine learning
approaches to detection of gene interactions. Our method is based upon
training a supervised learning algorithm to detect disease, and then
quantifying the effect on prediction accuracy when alleles of two or
more genes are perturbed to unmutated in patterns so as to reveal and
characterize gene interactions. We utilize this approach with both a
neural network and a support vector machine.&lt;/p&gt;
&lt;p&gt;We test the versatility of our approach using seven disease models, some
of which model gene interactions and some of which model biological
independence. In every disease model we correctly detect the presence or
absence of 2-way and 3-way gene interactions using our method with both
neural network and support vector machine. We also correctly
characterize all of the interactions as to the epistatic effect of gene
alleles in both 2-way and 3-way gene interactions. We conclude that
machine learning approaches can be used to successfully detect and also
characterize gene interactions in disease.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lin Wang</dc:creator><pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-07-01:scipy-2013/detection-and-characterization-of-interactions-of-.html</guid><category>bioinformatics</category><category>machine learning</category></item><item><title>Intergrating Pylearn2 and Hyperopt: Taking Deep Learning Further with Hyperparamter Optimization</title><link>http://pyvideo.org/scipy-2014/intergrating-pylearn2-and-hyperopt-taking-deep-l.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;This talk/poster will outline and present recent work in integrating
Hyperopt, a package for the optimization of the hyperparameters of
machine learning algorithms, with Pylearn2, a machine learning research
and prototyping framework focused on &amp;quot;deep learning&amp;quot; algorithms, the
technical challenges we faced and how we addressed them.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep learning algorithms have recently garnered much attention for their
successes in solving very difficult industrial machine perception
problems. However, for many practical purposes, these algorithms are
unwieldy due to the rapid proliferation of &amp;quot;hyperparameters&amp;quot; in their
specification -- architectural and optimization constants which
ordinarily must be specified a priori by the practitioner. There is a
growing interest within the machine learning community, and acutely so
amongst deep learning researchers, in intelligently automating the
selection of hyperparameters for machine learning algorithms by through
the use of sequential model-based optimization techniques.
[Hyperopt][&lt;a class="reference external" href="http://hyperopt.github.io/hyperopt/"&gt;http://hyperopt.github.io/hyperopt/&lt;/a&gt;] is software package
designed for this purpose, architected as a general framework for
hyperparameter optimization algorithms with support for complicated,
awkward hyperparameter spaces that, e.g., involve many hyperparameters
that are only meaningful in the context of certain values of other
hyperparameters.&lt;/p&gt;
&lt;p&gt;[Pylearn2][&lt;a class="reference external" href="http://deeplearning.net/software/pylearn2"&gt;http://deeplearning.net/software/pylearn2&lt;/a&gt;] is a framework for
machine learning developed by the LISA laboratory at Université de
Montréal; it is a research and prototyping library aimed primarily at
machine learning researchers, with a focus on &amp;quot;deep learning&amp;quot;
algorithms. Despite being far from a stable release, it has had
considerable impact and developed a very active user community outside
of the laboratory that birthed it.&lt;/p&gt;
&lt;p&gt;This talk will deecribe recent efforts in building a flexible,
user-friendly bridge between Pylearn2 and Hyperopt for the purpose of
optimizing the hyperparameters of deep learning algorithms. Briefly, it
will outline the relevant problem domain and the two packages, the
technical challenges we've met in adapting the two for use with one
another and our solutions to them, in particular the development of a
novel common deferred evaluation/call-graph description language based
on &lt;tt class="docutils literal"&gt;functools.partial&lt;/tt&gt;, which we hope to make available in the near
future as a standalone package.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David Warde-Farley</dc:creator><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-09:scipy-2014/intergrating-pylearn2-and-hyperopt-taking-deep-l.html</guid><category>machine learning</category></item><item><title>Statistical machine learning for text classification with scikit-learn</title><link>http://pyvideo.org/pycon-us-2011/pycon-2011--statistical-machine-learning-for-text.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Statistical machine learning for text classification with scikit-learn&lt;/p&gt;
&lt;p&gt;Presented by Olivier Grisel&lt;/p&gt;
&lt;p&gt;The goal of this talk is to give a state-of-the-art overview of machine
learning algorithms applied to text classification tasks ranging from
language and topic detection in tweets and web pages to sentiment
analysis in consumer products reviews.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Unstructured or semi-structured text data is ubiquitous thanks to the
read- write nature of the web. However human authors are often lazy and
don't fill- in structured metadata forms in web applications. It is
however possible to automate some structured knowledge extraction with
simple and scalable statistical learning tools implemented in python.
For instance:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;guessing the language and topic of tweets and web pages&lt;/li&gt;
&lt;li&gt;analyze the sentiment (positive or negative) in consumer products
reviews in blogs or customer emails&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This talk will introduce the main operational steps of supervised
learning:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;extracting the relevant features from text documents&lt;/li&gt;
&lt;li&gt;selecting the right machine learning algorithm to train a model for
the task at hand&lt;/li&gt;
&lt;li&gt;using the trained model on previously unseen documents&lt;/li&gt;
&lt;li&gt;evaluating the predictive accuracy of the trained model&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will also demonstrate the results obtained for above tasks using the
&lt;a class="reference external" href="http://scikit-learn.sourceforge.net/"&gt;scikit-learn&lt;/a&gt; package and
compare it to other implementations such as &lt;a class="reference external" href="http://nltk.org/"&gt;nltk&lt;/a&gt;
and the &lt;a class="reference external" href="http://code.google.com/apis/predict/"&gt;Google Prediction
API&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Olivier Grisel</dc:creator><pubDate>Fri, 11 Mar 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-03-11:pycon-us-2011/pycon-2011--statistical-machine-learning-for-text.html</guid><category>googlepredictionapi</category><category>machine learning</category><category>nltk</category><category>pycon</category><category>pycon2011</category><category>scikit-learn</category></item></channel></rss>