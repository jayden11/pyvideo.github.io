<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/tag_jupyter-notebook.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2016-10-09T00:00:00+00:00</updated><entry><title>Making your code faster: Cython and parallel processing in the Jupyter Notebook</title><link href="http://pyvideo.org/pydata-dc-2016/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Gustavo Patino</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/gapatino/Making-Your-Code-Faster-Cython-and-parallel-processing-in-the-Jupyter-Notebook"&gt;https://github.com/gapatino/Making-Your-Code-Faster-Cython-and-parallel-processing-in-the-Jupyter-Notebook&lt;/a&gt;
Slides: &lt;a class="reference external" href="http://www.slideshare.net/PyData/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook"&gt;http://www.slideshare.net/PyData/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As the complexity and scope of applications grow, it is very common to run into slow performance issues. In Python, it is possible to improve the speed of execution with the use of parallel processing and the Cython compiler. The Jupyter Notebook makes the implementation of both of them a relatively simple task, which will be the focus of this session.&lt;/p&gt;
</summary><category term="code"></category><category term="Cython"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="notebook"></category><category term="parallel"></category><category term="processing"></category></entry><entry><title>Popping Kernels: An Exploration of Kernel Development for Jupyter Notebooks</title><link href="http://pyvideo.org/pydata-chicago-2016/popping-kernels-an-exploration-of-kernel-development-for-jupyter-notebooks.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Safia Abdalla</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/popping-kernels-an-exploration-of-kernel-development-for-jupyter-notebooks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;This talk will give individuals with no kernel experience and some Python experience, a brief introduction to the concepts they need to understand in order to develop kernels. This talk will also be useful to individuals who are looking for fun projects that will allow them to strengthen their skills in a particular programming language.&lt;/p&gt;
</summary><category term="development"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>Setting up Python for machine learning: scikit-learn and IPython Notebook</title><link href="http://pyvideo.org/data-school/scikit-learn-02-machine-learning-setup.html" rel="alternate"></link><published>2015-04-15T00:00:00+00:00</published><updated>2015-04-15T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-04-15:data-school/scikit-learn-02-machine-learning-setup.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Want to get started with machine learning in Python? I'll discuss the pros and cons of the scikit-learn library, show how to install my preferred Python distribution, and demonstrate the basic functionality of the IPython Notebook. If you don't yet know any Python, I'll also provide four recommended resources for learning Python.&lt;/p&gt;
&lt;p&gt;This is the second video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="IPython notebook"></category><category term="Jupyter notebook"></category></entry><entry><title>Jupyter: Notebooks in Multiple Languages for Data Science</title><link href="http://pyvideo.org/pydata-amsterdam-2016/jupyter-notebooks-in-multiple-languages-for-data-science.html" rel="alternate"></link><published>2016-03-26T00:00:00+00:00</published><updated>2016-03-26T00:00:00+00:00</updated><author><name>Thomas Kluyver</name></author><id>tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/jupyter-notebooks-in-multiple-languages-for-data-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;We'll talk about how the Jupyter Notebook has evolved from a Python specific tool to a general data science tool that supports many different languages, and about our own experiences in supporting a wide variety of languages for data science. We'll also demonstrate some of the new features and ideas being developed in and around the project.&lt;/p&gt;
&lt;p&gt;Jupyter notebooks have become an invaluable tool for all kinds of data science. Originally developed as part of the IPython project, notebooks have evolved from a Python specific tool to support many programming languages; more than 50 different execution kernels have now been published. For all of these languages, notebooks are a way to record and describe a data science workflow, and then share it, publicly or privately, allowing the recipients to easily modify and execute the code.&lt;/p&gt;
&lt;p&gt;We’ll describe the architectural changes and decisions involved in the transition to supporting multiple languages, as well as our own experience in supporting data science languages ranging from C++ to R to Bash. You’ll also get a high-level understanding of how to create a new kernel, if a language you’re excited about is not yet supported.&lt;/p&gt;
&lt;p&gt;We’ll also highlight some of the current development work taking place in and around Jupyter, including redesigned UI, mechanisms for collaboration on notebooks, ways to share live, executable notebooks online, and projects that reuse the Jupyter machinery in different user interfaces.&lt;/p&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1PHnnkKYgjq1lcSDaVyhZP0Fs7qC70iA07b2Jv0uisUE/edit?usp=sharing"&gt;https://docs.google.com/presentation/d/1PHnnkKYgjq1lcSDaVyhZP0Fs7qC70iA07b2Jv0uisUE/edit?usp=sharing&lt;/a&gt;&lt;/p&gt;
</summary><category term="jupyter notebook"></category></entry><entry><title>Store and manage data effortlessly with HDF5</title><link href="http://pyvideo.org/pydata-amsterdam-2016/store-and-manage-data-effortlessly-with-hdf5.html" rel="alternate"></link><published>2016-03-26T00:00:00+00:00</published><updated>2016-03-26T00:00:00+00:00</updated><author><name>Margaret Mahan</name></author><id>tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/store-and-manage-data-effortlessly-with-hdf5.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;Are you looking for accessible, compressed, organized data? HDF5 might be the solution you’re looking for. HDF5 works like a file system within a file, designed for flexible and efficient storage and I/O for high volume, complex data. Come learn from a Pyentist how to leverage HDF5, get started with h5py, and see a real-world example of a processing pipeline utilizing HDF5.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Are you&lt;/p&gt;
&lt;p&gt;a Pyentist1?
frequently ‘grep’-ing?
drowning in ASCII files?
extending filenames for each processing step?
looking for accessible, compressed, organized data?
If you answered yes to any of these questions, then HDF5 might be the solution you’re looking for. HDF5 is entirely open source and supported by a variety of programming languages and tools, including Python (h5py). HDF5 not only supports large, complex, heterogeneous data but is self-describing and supports data slicing. In this talk, you’ll learn about embracing HDF5 from a Pyentist.&lt;/p&gt;
&lt;p&gt;This talk is aimed at data scientists who have large, numerical datasets that need to be managed and stored but also accessed and processed efficiently. Basic knowledge of NumPy and UNIX will be useful for attendees but not required. Attendees will learn how to get started with h5py, as well as how to leverage HDF5 in order to attain accessible, compressed, and organized data.&lt;/p&gt;
&lt;p&gt;HDF5 stands for Hierarchical Data Format, version 5. It is a file format, library, and data model for storing and managing data. More simply, HDF5 can be described as a file system within a file. An HDF5 file contains two kinds of objects, namely, datasets and groups. Datasets work like NumPy arrays while groups work like dictionaries that hold datasets and other groups. In addition, objects can have attributes, or metadata. HDF5 is designed for flexible and efficient storage and I/O for high volume, complex data. Data scientists will find HDF5 to be invaluable for managing, manipulating, and storing their data.&lt;/p&gt;
&lt;p&gt;Part of this talk will demonstrate how to get started with HDF5. In this demo, attendees will learn how to: create and handle HDF5 files using h5py, manage and manipulate datasets, work with groups, and make use of attributes. A real-world example of a processing pipeline of brain recordings, utilizing HDF5 for storing and managing data at each processing step, will be presented. Attendees will have access to an IPython notebook to follow along during the demo and explore examples. After this talk, attendees will be able to begin using HDF5 to effortlessly store and manage their data.&lt;/p&gt;
</summary><category term="hdf5"></category><category term="h5py"></category><category term="jupyter notebook"></category></entry><entry><title>Diffing and Merging Jupyter Notebooks with nbdime</title><link href="http://pyvideo.org/scipy-2016/diffing-and-merging-jupyter-notebooks-with-nbdime-scipy-2016-min-ragan-kelley.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Min Ragan Kelley</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/diffing-and-merging-jupyter-notebooks-with-nbdime-scipy-2016-min-ragan-kelley.html</id><summary type="html"></summary><category term="SciPy 2016"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>JupyterLab: Building Blocks for Interactive Computing</title><link href="http://pyvideo.org/scipy-2016/jupyterlab-building-blocks-for-interactive-computing-scipy-2016-brian-granger.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Brian Granger</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/jupyterlab-building-blocks-for-interactive-computing-scipy-2016-brian-granger.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Project Jupyter provides building blocks for interactive and exploratory computing. These building blocks make science and data science reproducible across over 40 programming language (Python, Julia, R, etc.). Central to the project is the Jupyter Notebook, a web-based interactive computing platform that allows users to author data- and code-driven narratives - computational narratives - that combine live code, equations, narrative text, visualizations, interactive dashboards and other media.&lt;/p&gt;
&lt;p&gt;While the Jupyter Notebook has proved to be an incredibly productive way of working with code and data interactively, it is helpful to decompose notebooks into more primitive building blocks: kernels for code execution, input areas for typing code, markdown cells for composing narrative content, output areas for showing results, terminals, etc. The fundamental idea of JupyterLab is to offer a user interface that allows users to assemble these building blocks in different ways to support interactive workflows that include, but go far beyond, Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;JupyterLab accomplishes this by providing a modular and extensible user interface that exposes these building blocks in the context of a powerful work space. Users can arrange multiple notebooks, text editors, terminals, output areas, etc. on a single page with multiple panels, tabs, splitters, and collapsible sidebars with a file browser, command palette and integrated help system. The codebase and UI of JupyterLab is based on a flexible plugin system that makes it easy to extend with new components.&lt;/p&gt;
&lt;p&gt;In this talk, we will demonstrate the JupyterLab interface, its codebase, and describe how it fits within the overall roadmap of the project.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="jupyter"></category><category term="jupyterlab"></category><category term="jupyter notebook"></category></entry><entry><title>Keynote: Project Jupyter</title><link href="http://pyvideo.org/scipy-2016/keynote-project-jupyter-scipy-2016-brian-granger.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Brian Granger</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/keynote-project-jupyter-scipy-2016-brian-granger.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Brian Granger is an Associate Professor of Physics at Cal Poly State University in San Luis Obispo, CA. He has a background in theoretical physics, with a Ph.D from the University of Colorado. His current research interests include quantum computing, parallel and distributed computing and interactive computing environments for scientific computing and data science. He is a leader of the IPython project, co-founder of Project Jupyter and is an active contributor to a number of other open source projects focused on data science in Python. He is a board member of the NumFocus Foundation and a fellow at Cal Poly’s Center for Innovation and Entrepreneurship. He is &amp;#64;ellisonbg on Twitter and GitHub.&lt;/p&gt;
&lt;p&gt;Announcement of Altair, Altair is a declarative statistical visualization library for Python. Altair is developed by Brian Granger and Jake Vanderplas in close collaboration with the UW Interactive Data Lab.&lt;/p&gt;
&lt;p&gt;With Altair, you can spend more time understanding your data and its meaning. Altair's API is simple, friendly and consistent and built on top of the powerful Vega-Lite JSON specification. This elegant simplicity produces beautiful and effective visualizations with a minimal amount of code.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="altair"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>Labs in the Wild: Teaching Signal Processing Using Wearables &amp; Jupyter Notebooks</title><link href="http://pyvideo.org/scipy-2016/labs-in-the-wild-teaching-signal-processing-using-wearables-jupyter-notebooks-scipy-2016.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Demba Ba</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/labs-in-the-wild-teaching-signal-processing-using-wearables-jupyter-notebooks-scipy-2016.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks and the Python ecosystem provide a unique opportunity for interactive, web-based, teaching of content that has not traditionally leveraged scientific computing resources. We discuss the design and implementation of a new biological signal processing course at Harvard, ES155, which fuses Wearable technology and cloud-based analysis of data. ES155 bridges the gap that has traditionally existed between Electrical Engineering and Computer Science education, in a framework that we term “Labs in the Wild”. In the process of designing the course, we have had to solve the problem of serving Jupyter notebooks on the cloud reliably using AWS EC2 instances. This is a challenging problem because a successful approach must be scalable, cost-effective, reliable, and address the privacy concerns associated with cloud-based technologies. We describe our system in this talk, and perform a live demo of how students in our class interact with the system, and give examples of ingenious final projects put together by students. Being cloud-based, our system lowers the barrier of entry for students to begin using Python for scientific computing.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="jupyter notebook"></category><category term="wearable"></category><category term="education"></category></entry><entry><title>How to “Scrape” Together a Great Dataset Using Things You Find on the Internet Using Python &amp; SciP</title><link href="http://pyvideo.org/scipy-2016/how-to-scrape-together-a-great-dataset-using-things-you-find-on-the-internet-using-python-scip.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Deborah Hanus</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/how-to-scrape-together-a-great-dataset-using-things-you-find-on-the-internet-using-python-scip.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Using Jupyter notebooks and scikit-learn, you’ll predict whether a movie is likely to win an Oscar or be a box office hit. I’ll walk through the most important steps of creating an effective dataset using information that you find on the Internet: asking a question your data can answer, writing a web scraper, and answering those questions using nothing but Python libraries and data from the Internet. To illustrate how these steps fit together, I walk through building a dataset from IMDB data and use it to predict &lt;a class="reference external" href="http://oscarpredictor.github.io/"&gt;what makes a winning Oscar movie&lt;/a&gt;. To preview our findings, check out &lt;a class="reference external" href="https://youtu.be/84IZ8Gn6PJ"&gt;this trailer&lt;/a&gt; and the &lt;a class="reference external" href="https://github.com/oscarpredictor/oscar-predictor"&gt;github repository&lt;/a&gt;!&lt;/p&gt;
</summary><category term="scrapping"></category><category term="oscarpredictor"></category><category term="jupyter notebook"></category><category term="scikit-learn"></category></entry><entry><title>JupyterHub as an Interactive Supercomputing Gateway</title><link href="http://pyvideo.org/scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Michael Milligan</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At the Minnesota Supercomputing Institute we are exploring ways to provide the immediacy and flexibility of interactive computing within the batch-scheduled, tightly controlled world of traditional cluster supercomputing. As Jupyter Notebook has gained in popularity, the steps needed to use it within such an environment have proven to be a barrier to entry even as increasingly powerful Python tools have developed to take advantage of large computational resources. JupyterHub to the rescue! Except out of the box, it doesn't know anything about resource types, job submission, and so on. We developed BatchSpawner and friends as a general JupyterHub backend for batch-scheduled environments. In this talk I will walk through how we have deployed JupyterHub to provide a user-friendly gateway to interactive supercomputing.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="hpc"></category><category term="jupyterhub"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="supercomputing"></category></entry><entry><title>Reproducible, One Button Workflows with the Jupyter Notebook &amp; Scons</title><link href="http://pyvideo.org/scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Jessica Hamrick</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What is the best way to develop analysis code in the Jupyter notebook, while managing complex dependencies between analyses? In this talk, I will introduce nbflow, which is a project that integrates a Python-based build system (SCons) with the Jupyter notebook, enabling researchers to easily build sophisticated,
complex analysis pipelines entirely within notebooks while still maintaining a &amp;quot;one-button workflow&amp;quot; in which all analyses can be executed, in the correct order, from a single command. I will show how nbflow can be applied to existing analyses and how it can be used to construct an analysis pipeline stretching the entire way from data cleaning, to computing statistics, to generating figures,
and even to automatically generating LaTeX commands that can be used in publications to format results without the risk of copy-and-paste error.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="workflow"></category><category term="nbflow"></category></entry><entry><title>Sharing Reproducible Environments with Binder</title><link href="http://pyvideo.org/scipy-2016/sharing-reproducible-environments-with-binder-scipy-2016-andrew-osheroff.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Andrew Osheroff</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/sharing-reproducible-environments-with-binder-scipy-2016-andrew-osheroff.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Binder (&lt;a class="reference external" href="http://mybinder.org"&gt;http://mybinder.org&lt;/a&gt;) is a service that bundles GitHub repositories with code, Jupyter notebooks, and data into reproducible, executable environments that can be launched instantaneously in the browser with the click of a button. Under the hood, Binder uses simple and flexible dependency specifications to build Docker images on demand, and then launches and schedules them across a public Kubernetes cluster. In this talk, I’ll describe in detail how Binder works, and highlight some exciting use cases. I’ll then describe several future directions for the project, including handling larger datasets, lowering barriers for environment specification, and supporting custom deployments with user-provided computing resources.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="binder"></category><category term="jupyter notebook"></category></entry></feed>