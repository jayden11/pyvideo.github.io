<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/tag_bigdata.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2012-08-22T00:00:00+00:00</updated><entry><title>Big data with python</title><link href="http://pyvideo.org/pycon-au-2012/big-data-with-python.html" rel="alternate"></link><published>2012-08-22T00:00:00+00:00</published><updated>2012-08-22T00:00:00+00:00</updated><author><name>Alex Sharp</name></author><id>tag:pyvideo.org,2012-08-22:pycon-au-2012/big-data-with-python.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Dealing with big data isn't a particularly new problem. There are all
sorts of new solutions, each with their own niche, their own hype. It's
important to remember that python is not &amp;quot;too slow&amp;quot; for big data, and
that with projects such as&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dealing with big data isn't a particularly new problem. There are all
sorts of new solutions, each with their own niche, their own hype. It's
important to remember that python is not &amp;quot;too slow&amp;quot; for big data, and
that with projects such as scipy, numpy, cython and rpy, python is
becoming a better tool then ever for data processing. In this talk we'll
be explaining some of the theory behind big data problems, where python
fits in and some of the more interesting things you can do.&lt;/p&gt;
</summary><category term="bigdata"></category></entry><entry><title>Backup Is Hard; Let's Go Shopping</title><link href="http://pyvideo.org/pycon-us-2011/pycon-2011--backup-is-hard--let--39-s-go-shopping.html" rel="alternate"></link><published>2011-03-11T00:00:00+00:00</published><updated>2011-03-11T00:00:00+00:00</updated><author><name>Gary Bernhardt</name></author><id>tag:pyvideo.org,2011-03-11:pycon-us-2011/pycon-2011--backup-is-hard--let--39-s-go-shopping.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Backup Is Hard; Let's Go Shopping&lt;/p&gt;
&lt;p&gt;Presented by Gary Bernhardt&lt;/p&gt;
&lt;p&gt;We'll fly through the most clever bits of BitBacker, an online backup
app developed as a startup for three years and eventually abandoned.
Highlights: a hacked-up httplib/asyncore HTTP client; a real-life,
HATEOAS-respecting RESTful API, and an encryption scheme that can
quickly diff a file system against the server while leaking no
information – not even file timestamps.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;This is the story of a solution to a huge problem: fast, secure online
backup. A single client generates a hundred gigabytes, millions of data
chunks, and thousands of file system snapshots. To appreciate the
problem's scale, consider that a Python array holding content hashes for
1,000,000 files consumes 100 MB of memory. File hashes are only a
portion of the required per- file metadata, and that's only one for
snapshot of thousands.&lt;/p&gt;
&lt;p&gt;We'll tour the hard parts of this system with no apology for their
difficulty. The httplib/asyncore hybrid monster that served millions of
parallel requests, transparently retrying on failures and timeouts, with
only 300 lines of python. The RESTful API – fully respecting hypertext,
with every request safely repeatable, even POSTs, and not a single
hard-coded URL in the client. The encryption scheme that leaked nothing
– not even modification times – but could quickly diff local file
systems against the server. And, that one time that a client
accidentally requested a 4.76 megabyte URL in production.&lt;/p&gt;
</summary><category term="backup"></category><category term="bigdata"></category><category term="bitbacker"></category><category term="pycon"></category><category term="pycon2011"></category></entry><entry><title>Handling ridiculous amounts of data with probabilistic data structures</title><link href="http://pyvideo.org/pycon-us-2011/pycon-2011--handling-ridiculous-amounts-of-data-w.html" rel="alternate"></link><published>2011-03-11T00:00:00+00:00</published><updated>2011-03-11T00:00:00+00:00</updated><author><name>C. Titus Brown</name></author><id>tag:pyvideo.org,2011-03-11:pycon-us-2011/pycon-2011--handling-ridiculous-amounts-of-data-w.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Handling ridiculous amounts of data with probabilistic data structures&lt;/p&gt;
&lt;p&gt;Presented by C. Titus Brown&lt;/p&gt;
&lt;p&gt;Part of my job as a scientist involves playing with rather large amounts
of data (200 gb+). In doing so we stumbled across some neat CS
techniques that scale well, and are easy to understand and trivial to
implement. These techniques allow us to make some or many types of data
analysis map-reducable. I'll talk about interesting implementation
details, fun science, and neat computer science.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;If an extreme talk, I will talk about interesting details/issues in:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Python as the backbone for a non-SciPy scientific software package:
using Python as a frontend to C++ code, esp for parallelization and
testing purposes.&lt;/li&gt;
&lt;li&gt;Implementing probabilistic data structures with one-sided error as
pre-filters for data retrieval and analysis, in ways that are
generally useful.&lt;/li&gt;
&lt;li&gt;Efficiently breaking down certain types of sparse graph problems
using these probabilistic data structures, so that large graphs can
be analyzed straightforwardly. This will be applied to plagiarism
detection and/or duplicate code detection.&lt;/li&gt;
&lt;/ol&gt;
</summary><category term="bigdata"></category><category term="parallelization"></category><category term="pycon"></category><category term="pycon2011"></category><category term="testing"></category></entry><entry><title>Rapid Python used on Big Data to Discover Human Genetic Variation</title><link href="http://pyvideo.org/pycon-us-2011/pycon-2011--rapid-python-used-on-big-data-to-disc.html" rel="alternate"></link><published>2011-03-11T00:00:00+00:00</published><updated>2011-03-11T00:00:00+00:00</updated><author><name>Deniz Kural</name></author><id>tag:pyvideo.org,2011-03-11:pycon-us-2011/pycon-2011--rapid-python-used-on-big-data-to-disc.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Rapid Python used on Big Data to Discover Human Genetic Variation&lt;/p&gt;
&lt;p&gt;Presented by Deniz Kural&lt;/p&gt;
&lt;p&gt;Advances in genome sequencing has enabled large-scale projects such as
the 1000 Genomes Project to sequence genomes across diverse populations
around the world, resulting in very large data sets. I use Python for
rapid development of algorithms for processing &amp;amp; analyzing genomes and
discovering thousands of new variants, including &amp;quot;Mobile Elements&amp;quot; that
copy&amp;amp;paste; themselves across the genome.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Recent advances in high-throughput sequencing now enables accurate
sequencing human genomes at a low cost &amp;amp; high speed. This technology is
now used to initiate projects involving large-scale sequencing of many
genomes. The 1000 Genomes project aims to sequence 2500 genomes across
27 world populations, and has initially completed its Pilot phase. The
aim of the project is to discover &amp;amp; characterize novel variants. These
variants enable association studies that investigate the link between
genomic variation &amp;amp; phenotypes, including disease.&lt;/p&gt;
&lt;p&gt;A class of variants, known as &amp;quot;Structural Variants&amp;quot; represent a
heterogenous class of larger variants, such as inversions, duplications,
deletions, and various kinds of insertions.&lt;/p&gt;
&lt;p&gt;I use Python to for rapid development of algorithms to process, analyze,
and annotate very large data sets. In particular, I focus on Mobile
Elements, pieces of DNA that copy&amp;amp;paste; across the genome. These
elements constitute roughly half of the genome, whereas protein-coding
genes account for roughly 1.5 % of the genome.&lt;/p&gt;
&lt;p&gt;I will discuss distributed computing, genomics, and big data within the
context of Python.&lt;/p&gt;
</summary><category term="bigdata"></category><category term="casestudy"></category><category term="dna"></category><category term="genomes"></category><category term="pycon"></category><category term="pycon2011"></category></entry></feed>