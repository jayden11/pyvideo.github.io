<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="http://pyvideo.org/" rel="alternate"></link><link href="http://pyvideo.org/feeds/tag_search.atom.xml" rel="self"></link><id>http://pyvideo.org/</id><updated>2016-10-08T00:00:00+00:00</updated><entry><title>Fuzzy Search Algorithms How and When to Use Them</title><link href="http://pyvideo.org/pydata-dc-2016/fuzzy-search-algorithms-how-and-when-to-use-them.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Jiaqi Liu</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/fuzzy-search-algorithms-how-and-when-to-use-them.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;So much of data science is about understanding the context around your data. In this talk, we hope to address how to work with messy text data by leveraging fuzzy search algorithms in python or against a database such as PostgreSQL. We will talk specifically about fuzzy algorithms such as Soundex, Trigram/n-gram search, and Levenshtein distances and demonstrate use cases in an ipython notebook.&lt;/p&gt;
</summary><category term="search"></category></entry><entry><title>Implementing distributed grid search for deep learning using scikit learn and joblib</title><link href="http://pyvideo.org/pydata-chicago-2016/implementing-distributed-grid-search-for-deep-learning-using-scikit-learn-and-joblib.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Mike Heilman</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/implementing-distributed-grid-search-for-deep-learning-using-scikit-learn-and-joblib.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://mheilman.github.io/pydata_chicago_2016/#/"&gt;https://mheilman.github.io/pydata_chicago_2016/#/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Grid search over hyperparameters is an important but computationally expensive process in machine learning, particularly for deep learning and tree ensembles. In this talk, I will describe how one can use joblib's recently added custom backend functionality to do distributed grid search on Amazon EC2 for a TensorFlow deep text classifier that follows the scikit-learn estimator API.&lt;/p&gt;
</summary><category term="deep learning"></category><category term="distributed"></category><category term="learning"></category><category term="scikit"></category><category term="search"></category></entry><entry><title>Add a search engine to your application using Xapian</title><link href="http://pyvideo.org/pytexas-2015/add-a-search-engine-to-your-application-using-xap.html" rel="alternate"></link><published>2015-10-09T00:00:00+00:00</published><updated>2015-10-09T00:00:00+00:00</updated><author><name>Ying Rou Zhao</name></author><id>tag:pyvideo.org,2015-10-09:pytexas-2015/add-a-search-engine-to-your-application-using-xap.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Search is a key component of most modern web and mobile applications. If
you want to add a full text search engine to your Python application and
effectively search large volumes of unstructured text, you could use
Xapian which is an open-source, light-weight and very fast C++ library.
Targeted to Python developers, this talk aims at introducing Xapian and
its Python bindings along with basic search concepts. We will show how
to build your search engine using Xapian step by step. Topics such as
indexing, stemming, querying and faceting techniques will be discussed
with code samples. A working prototype of a search engine built with
Xapian will be demonstrated in the end.&lt;/p&gt;
&lt;p&gt;demo repo: &lt;a class="reference external" href="https://github.com/jingle3276/imdb250"&gt;https://github.com/jingle3276/imdb250&lt;/a&gt; slides:
&lt;a class="reference external" href="https://docs.google.com/presentation/d/1wQVQig5Vdj5unQAkQQI8mELmX2zqjQ6S9OqeQIDqgoc/edit#slide=id.p"&gt;https://docs.google.com/presentation/d/1wQVQig5Vdj5unQAkQQI8mELmX2zqjQ6S9OqeQIDqgoc/edit#slide=id.p&lt;/a&gt;&lt;/p&gt;
</summary><category term="search"></category></entry><entry><title>Large Problems in Django, Mostly Solved</title><link href="http://pyvideo.org/djangocon-2010/djangocon-2010--large-problems-in-django--mostly-.html" rel="alternate"></link><published>2010-09-08T00:00:00+00:00</published><updated>2010-09-08T00:00:00+00:00</updated><author><name>Eric Holscher</name></author><id>tag:pyvideo.org,2010-09-08:djangocon-2010/djangocon-2010--large-problems-in-django--mostly-.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk is based on my popular series of blog posts highlighting
applications from the community. I will highlight some of the best
applications that the Django/Python community has put together, talk
about places that are lacking, and talk about what these popular
applications have in common.&lt;/p&gt;
&lt;p&gt;Part 1&lt;/p&gt;
&lt;p&gt;I have written a series of blog posts about &amp;quot;Large problems&amp;quot; in the
community, and how they have been solved by members of our community
with reusable apps. Previously I have covered:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Delayed Execution&lt;/li&gt;
&lt;li&gt;Search&lt;/li&gt;
&lt;li&gt;APIs&lt;/li&gt;
&lt;li&gt;Documentation&lt;/li&gt;
&lt;li&gt;Database Migrations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will update my thoughts on these issues, as well as talking about a
couple of other new issues that I think that have been solved in a
decent way. These include:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Remote Command Execution&lt;/li&gt;
&lt;li&gt;Debugging in Development&lt;/li&gt;
&lt;li&gt;Continuous Integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 2&lt;/p&gt;
&lt;p&gt;In this part I will highlight issues that are still headaches for the
Community. These are places where there is a good chance for growth for
third party apps, and places where I have personally found some friction
in my development. A couple examples of this are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Deployment&lt;/li&gt;
&lt;li&gt;Class Based Views / Thread Safety&lt;/li&gt;
&lt;li&gt;Debugging Production Environments&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 3&lt;/p&gt;
&lt;p&gt;From the above applications that are well done, what makes a popular
reusable app? This won't be my thoughts, but more looking at apps that
have been successful and trying to see what they have in common. A good
app and a good reusable app are necessarily different, and I think it
will be interesting to look at what traits make reusable apps popular.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://ericholscher.com/tag/largeproblems/"&gt;Large problems posts&lt;/a&gt;&lt;/p&gt;
</summary><category term="api"></category><category term="ci"></category><category term="continuousintegration"></category><category term="databasemigrations"></category><category term="debugging"></category><category term="delayedexecutions"></category><category term="deployment"></category><category term="djangocon"></category><category term="djangocon2010"></category><category term="documentation"></category><category term="migrations"></category><category term="safety"></category><category term="search"></category></entry><entry><title>Beyond Python Enhanced Generators</title><link href="http://pyvideo.org/europython-2011/beyond-python-enhanced-generators.html" rel="alternate"></link><published>2011-07-24T00:00:00+00:00</published><updated>2011-07-24T00:00:00+00:00</updated><author><name>Erik Groeneveld</name></author><id>tag:pyvideo.org,2011-07-24:europython-2011/beyond-python-enhanced-generators.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Erik Groeneveld - 23 June 2011 in &amp;quot;Track Spaghetti&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Right after the introduction of PEP342 (Enhanced Generators) we started
to decompose programs into generators. It was soon discovered that for
real-life problems one would need something like &amp;quot;yield from&amp;quot;, as is
described in PEP380. At that time, we already had a similar solution
called '&lt;a class="reference external" href="http://weightless.io/compose"&gt;compose&lt;/a&gt;', which we adapted
to PEP380.&lt;/p&gt;
&lt;p&gt;After 5 years working with 'compose', we found a small set of other
features that are essential if you want to use Enhanced Generators not
only as a way of lightweight command scheduling, but also a a pipe-line,
or parser. Indeed, the latter concepts are what real co-routines are
about.&lt;/p&gt;
&lt;p&gt;This talk introduces what is needed on top of PEPs 342 and 380 based on
experience with decomposing big enterprise search engines into
co-routines. Parts of it have been presented on SPA (2008) and
EuroPython (2010). Understanding of Enhanced Generators is a
prerequisite.&lt;/p&gt;
&lt;p&gt;Experience has shown that the topic is subtle enough to require quite
some time for full understanding, hence the suggestion for a 90 min
slot.&lt;/p&gt;
</summary><category term="generators"></category><category term="search"></category></entry><entry><title>Scraping Techniques to Extract Advertisements from Web Pages</title><link href="http://pyvideo.org/europython-2011/scraping-techniques-to-extract-advertisements-fro.html" rel="alternate"></link><published>2011-07-24T00:00:00+00:00</published><updated>2011-07-24T00:00:00+00:00</updated><author><name>Mirko Urru</name></author><id>tag:pyvideo.org,2011-07-24:europython-2011/scraping-techniques-to-extract-advertisements-fro.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Mirko Urru,Stefano Cotta Ramusino - 24 June 2011 in
&amp;quot;Track Tagliatelle &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Online Advertising is an emerging research field, at the intersection of
Information Retrieval, Machine Learning, Optimization, and
Microeconomics. Its main goal is to choose the right ads to present to a
user engaged in a given task, such as Sponsored Search Advertising or
Contextual Advertising. The former puts ads on the page returned from a
Web search engine following a query. The latter puts ads within the
content of a generic, third party, Web page. The ads themselves are
selected and served by automated systems based on the content displayed
to the user.&lt;/p&gt;
&lt;p&gt;Web scraping is the set of techniques used to automatically get some
information from a website instead of manually copying it. In
particular, we're interested in studying and adopting scraping
techniques for: i. accessing tags as object members ii. finding out tags
whose name, contents or attributes match selection criteria iii.
accessing tag attributes by using a dictionary-like syntax.&lt;/p&gt;
&lt;p&gt;In this talk, we focus on the adoption of scraping techniques in the
contextual advertising field. In particular, we present a system aimed
at finding the most relevant ads for a generic web page p. Starting from
p, the system selects a set of its inlinks (i.e., the pages that link p)
and extracts the ads contained into them. Selection is performed
querying the Google search engine, whereas extraction is made by using
suitable scraping techniques.&lt;/p&gt;
</summary><category term="google"></category><category term="scraping"></category><category term="search"></category><category term="web"></category></entry><entry><title>django-rdflib and postgresql - the best of both worlds</title><link href="http://pyvideo.org/europython-2011/django-rdflib-and-postgresql-the-best-of-both-w.html" rel="alternate"></link><published>2011-07-13T00:00:00+00:00</published><updated>2011-07-13T00:00:00+00:00</updated><author><name>Stefan Talpalaru</name></author><id>tag:pyvideo.org,2011-07-13:europython-2011/django-rdflib-and-postgresql-the-best-of-both-w.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Stefan Talpalaru - 21 June 2011 in &amp;quot;Track Ravioli&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;rdflib is a python library implementing a database with various triples
back- end, parser, data serializers, SPARQL is a Python interface to
extract/insert triples. We integrated it in Django reusing the database
connection and exposing an ORM interface, along with full-text search on
literals. This presentation shows a django-rdflib case study with a
PostgreSQL backend in &lt;a class="reference external" href="http://brancusi1.usc.edu"&gt;Brain Architecture Management
System&lt;/a&gt; - a neuroscientific project for the
University of Southern California. Benefits of the flexible RDF
structure will be shown, allowing researchers to insert free format
data, making data public with a customizable serialization and use the
powerful full-text search integrated in PostgreSQL.&lt;/p&gt;
&lt;p&gt;Objective: show attendees an effective combination of RDF, PostgreSQL
full- text search and Django ORM via django-rdflib.&lt;/p&gt;
&lt;p&gt;Requirements: Django familiarity.&lt;/p&gt;
</summary><category term="architecture"></category><category term="database"></category><category term="django"></category><category term="orm"></category><category term="postgresql"></category><category term="reusing"></category><category term="search"></category><category term="serialization"></category><category term="university"></category></entry><entry><title>Komponenten einer komplexen Web-Applikation</title><link href="http://pyvideo.org/pycon-de-2013/komponenten-einer-komplexen-web-applikation.html" rel="alternate"></link><published>2013-10-16T00:00:00+00:00</published><updated>2013-10-16T00:00:00+00:00</updated><author><name>Daniel Hepper</name></author><id>tag:pyvideo.org,2013-10-16:pycon-de-2013/komponenten-einer-komplexen-web-applikation.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Komplexe Web-Applikationen bestehen aus mehr als einem Webserver, einer
Datenbank und etwas Code. Dieser Vortrag gibt einen Überblick über die
typischen Bausteine wie Celery als Task Queue, Haystack für
Volltextsuche, Sentry als Log-Diensten und automatischem Deployment mit
Fabric und Salt. Die vorgestellte Komponenten werden anhand einer
Django-Applikation erläutert, sind jedoch zum Großteil auch mit anderen
Frameworks nutzbar.&lt;/p&gt;
</summary><category term="celery"></category><category term="deployment"></category><category term="django"></category><category term="elasticsearch"></category><category term="fabric"></category><category term="haystack"></category><category term="salt"></category><category term="search"></category><category term="sentry"></category><category term="solr"></category></entry></feed>