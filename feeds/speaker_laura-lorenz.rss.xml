<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>http://pyvideo.org/</link><description></description><lastBuildDate>Sat, 08 Oct 2016 00:00:00 +0000</lastBuildDate><item><title>How I learned to time travel, or, data pipelining and scheduling with Airflow</title><link>http://pyvideo.org/pydata-dc-2016/how-i-learned-to-time-travel-or-data-pipelining-and-scheduling-with-airflow.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/PyData/how-i-learned-to-time-travel-or-data-pipelining-and-scheduling-with-airflow-67650418"&gt;http://www.slideshare.net/PyData/how-i-learned-to-time-travel-or-data-pipelining-and-scheduling-with-airflow-67650418&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data warehousing and analytics projects can, like ours, start out small - and fragile. With an organically growing mess of scripts glued together and triggered by cron jobs hiding on different servers, we needed better plumbing. After perusing the data pipelining landscape, we landed on Airflow, an Apache incubating batch processing pipelining and scheduler tool from Airbnb.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Laura Lorenz</dc:creator><pubDate>Sat, 08 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-08:pydata-dc-2016/how-i-learned-to-time-travel-or-data-pipelining-and-scheduling-with-airflow.html</guid><category>airflow</category><category>Data</category></item><item><title>Natural Language Processing with NLTK and Gensim</title><link>http://pyvideo.org/pycon-us-2016/tony-ojeda-benjamin-bengfort-laura-lorenz-natural-language-processing-with-nltk-and-gensim.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speakers: Tony Ojeda, Benjamin Bengfort, Laura Lorenz&lt;/p&gt;
&lt;p&gt;In this tutorial, we will begin by exploring the features of the NLTK library. We will then focus on building a language-aware data product - a topic identification and document clustering algorithm from a web crawl of blog sites. The clustering algorithm will use a simple Lesk K-Means clustering to start, and then will improve with an LDA analysis using the popular Gensim library.&lt;/p&gt;
&lt;p&gt;Slides can be found at: &lt;a class="reference external" href="https://speakerdeck.com/pycon2016"&gt;https://speakerdeck.com/pycon2016&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/PyCon/2016-slides"&gt;https://github.com/PyCon/2016-slides&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tony Ojeda</dc:creator><pubDate>Mon, 30 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-30:pycon-us-2016/tony-ojeda-benjamin-bengfort-laura-lorenz-natural-language-processing-with-nltk-and-gensim.html</guid></item></channel></rss>